{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3bd818db-0d5f-4c22-9fe1-45707038e077",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bd818db-0d5f-4c22-9fe1-45707038e077",
        "outputId": "d269e842-c6bc-4478-9d1d-2763cd059820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: guardrails-ai in /home/levi/.local/lib/python3.10/site-packages (0.6.2)\n",
            "Requirement already satisfied: boto3<2,>1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.35.99)\n",
            "Requirement already satisfied: coloredlogs<16.0.0,>=15.0.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (15.0.1)\n",
            "Requirement already satisfied: diff-match-patch<20230431,>=20230430 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (20230430)\n",
            "Requirement already satisfied: faker<26.0.0,>=25.2.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (25.9.2)\n",
            "Requirement already satisfied: griffe<0.37.0,>=0.36.9 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.36.9)\n",
            "Requirement already satisfied: guardrails-api-client<0.5.0,>=0.4.0a1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.4.0a1)\n",
            "Requirement already satisfied: guardrails-hub-types<0.0.5,>=0.0.4 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.0.4)\n",
            "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.1.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (4.23.0)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.3.24)\n",
            "Requirement already satisfied: litellm<2.0.0,>=1.37.14 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.58.2)\n",
            "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (4.9.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.30.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.59.7)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.24.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.29.0)\n",
            "Requirement already satisfied: pip>=22 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (24.3.1)\n",
            "Requirement already satisfied: pydantic<3.0,>=2.0.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.9.2)\n",
            "Requirement already satisfied: pydash<8.0.0,>=7.0.6 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (7.0.7)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.10.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.32.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (13.8.0)\n",
            "Requirement already satisfied: rstr<4.0.0,>=3.2.2 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (3.2.2)\n",
            "Requirement already satisfied: semver<4.0.0,>=3.0.2 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=8.1.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.7.0)\n",
            "Requirement already satisfied: typer<0.13,>=0.9.0 in /home/levi/.local/lib/python3.10/site-packages (from typer[all]<0.13,>=0.9.0->guardrails-ai) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.8.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (4.12.2)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.99 in /home/levi/.local/lib/python3.10/site-packages (from boto3<2,>1->guardrails-ai) (1.35.99)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/levi/.local/lib/python3.10/site-packages (from boto3<2,>1->guardrails-ai) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/levi/.local/lib/python3.10/site-packages (from boto3<2,>1->guardrails-ai) (0.10.4)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /home/levi/.local/lib/python3.10/site-packages (from coloredlogs<16.0.0,>=15.0.1->guardrails-ai) (10.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /home/levi/.local/lib/python3.10/site-packages (from griffe<0.37.0,>=0.36.9->guardrails-ai) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-api-client<0.5.0,>=0.4.0a1->guardrails-ai) (75.8.0)\n",
            "Requirement already satisfied: urllib3<2.1.0,>=1.25.3 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-api-client<0.5.0,>=0.4.0a1->guardrails-ai) (2.0.7)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.19.1)\n",
            "Requirement already satisfied: fqdn in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.5.1)\n",
            "Requirement already satisfied: idna in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (3.10)\n",
            "Requirement already satisfied: isoduration in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (3.0.0)\n",
            "Requirement already satisfied: rfc3339-validator in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.1.4)\n",
            "Requirement already satisfied: rfc3987 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.3.8)\n",
            "Requirement already satisfied: uri-template in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=1.11 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (24.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (0.1.125)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (24.1)\n",
            "Requirement already satisfied: aiohttp in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.10.5)\n",
            "Requirement already satisfied: click in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (8.1.7)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.27.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (6.11.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.1.4)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (1.0.1)\n",
            "Requirement already satisfied: tokenizers in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.19.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.66.5)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.2.14)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.65.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.69.0)\n",
            "Requirement already satisfied: opentelemetry-api~=1.15 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.29.0)\n",
            "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-proto==1.29.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (5.29.3)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->guardrails-ai) (0.50b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/levi/.local/lib/python3.10/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /home/levi/.local/lib/python3.10/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /home/levi/.local/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->guardrails-ai) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/levi/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (3.3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/levi/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/levi/.local/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/levi/.local/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (2.18.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /home/levi/.local/lib/python3.10/site-packages (from tiktoken>=0.5.1->guardrails-ai) (2024.7.24)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /home/levi/.local/lib/python3.10/site-packages (from typer<0.13,>=0.9.0->typer[all]<0.13,>=0.9.0->guardrails-ai) (1.5.4)\n",
            "\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: exceptiongroup>=1.0.2 in /home/levi/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.30.1->guardrails-ai) (1.2.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /home/levi/.local/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.16.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/levi/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/levi/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/levi/.local/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/levi/.local/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.37.14->guardrails-ai) (2.1.5)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/levi/.local/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.1->guardrails-ai) (3.10.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/levi/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->guardrails-ai) (0.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.3.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (4.0.3)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /home/levi/.local/lib/python3.10/site-packages (from isoduration->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/levi/.local/lib/python3.10/site-packages (from tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.25.0)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/levi/.local/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (2.9.0.20240316)\n",
            "Requirement already satisfied: filelock in /home/levi/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/levi/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (2024.9.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: urllib3 in /home/levi/.local/lib/python3.10/site-packages (2.0.7)\n",
            "2025-01-22 17:14:23.573426: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-22 17:14:23.686089: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576863.740724    9397 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576863.755046    9397 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:14:23.885397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mdetect_pii...\u001b[0m\n",
            "\u001b[2K/home/levi/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: \n",
            "UserWarning: Setuptools is replacing distutils. Support for replacing an already\n",
            "imported distutils is deprecated. In the future, this condition will fail. \n",
            "Register concerns at \n",
            "https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "\u001b[2K\u001b[32m[   =]\u001b[0m Fetching manifest\n",
            "\u001b[2K\u001b[32m[=   ]\u001b[0m Downloading dependenciespendencies\n",
            "\u001b[2K\u001b[32m[==  ]\u001b[0m Running post-install setuptall setup\n",
            "\u001b[1A\u001b[2K✅Successfully installed guardrails/detect_pii version \u001b[1;36m0.0\u001b[0m.\u001b[1;36m5\u001b[0m!\n",
            "\n",
            "\n",
            "\u001b[1mImport validator:\u001b[0m\n",
            "from guardrails.hub import DetectPII\n",
            "\n",
            "\u001b[1mGet more info:\u001b[0m\n",
            "\u001b[4;94mhttps://hub.guardrailsai.com/validator/guardrails/detect_pii\u001b[0m\n",
            "\n",
            "2025-01-22 17:14:42.110691: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-22 17:14:42.130021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576882.145990    9462 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576882.150173    9462 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:14:42.166544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mteste...\u001b[0m\n",
            "ERROR:guardrails-cli:404\n",
            "ERROR:guardrails-cli:Not Found\n",
            "ERROR:guardrails-cli:Failed to install hub://guardrails/teste\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "2025-01-22 17:14:56.941546: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-22 17:14:56.952510: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576896.966449    9515 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576896.970379    9515 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:14:56.984327: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mpii...\u001b[0m\n",
            "ERROR:guardrails-cli:404\n",
            "ERROR:guardrails-cli:Not Found\n",
            "ERROR:guardrails-cli:Failed to install hub://guardrails/pii\n",
            "2025-01-22 17:15:04.697444: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-22 17:15:04.709506: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576904.724719    9541 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576904.729405    9541 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:15:04.751633: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mnsfw_text...\u001b[0m\n",
            "\u001b[2K/home/levi/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: \n",
            "UserWarning: Setuptools is replacing distutils. Support for replacing an already\n",
            "imported distutils is deprecated. In the future, this condition will fail. \n",
            "Register concerns at \n",
            "https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "\u001b[2K\u001b[32m[==  ]\u001b[0m Fetching manifest\n",
            "\u001b[2K\u001b[32m[==  ]\u001b[0m Downloading dependenciespendencies\n",
            "\u001b[2K\u001b[32m[=== ]\u001b[0m Running post-install setuptall setup2025-01-22 17:15:11.595493: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "\u001b[2K\u001b[32m[==  ]\u001b[0m Running post-install setup2025-01-22 17:15:11.606477: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576911.620578    9595 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576911.624709    9595 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:15:11.638384: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[2K\u001b[32m[=== ]\u001b[0m Running post-install setup/home/levi/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "\u001b[2K\u001b[32m[   =]\u001b[0m Running post-install setup\n",
            "\u001b[1A\u001b[2K✅Successfully installed guardrails/nsfw_text version \u001b[1;36m0.0\u001b[0m.\u001b[1;36m1\u001b[0m!\n",
            "\n",
            "\n",
            "\u001b[1mImport validator:\u001b[0m\n",
            "from guardrails.hub import NSFWText\n",
            "\n",
            "\u001b[1mGet more info:\u001b[0m\n",
            "\u001b[4;94mhttps://hub.guardrailsai.com/validator/guardrails/nsfw_text\u001b[0m\n",
            "\n",
            "2025-01-22 17:15:20.037340: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-22 17:15:20.048335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576920.062019    9622 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576920.065940    9622 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:15:20.079549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95msimilar_to_document...\u001b[0m\n",
            "/home/levi/.local/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "✅Successfully installed guardrails/similar_to_document version \u001b[1;36m0.0\u001b[0m.\u001b[1;36m0\u001b[0m!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!python3.10 -m pip install guardrails-ai\n",
        "!python3.10 -m pip install urllib3\n",
        "!guardrails hub install hub://guardrails/detect_pii\n",
        "!guardrails hub install hub://guardrails/teste --quiet\n",
        "!python3.10 -m spacy download pt_core_news_sm\n",
        "!guardrails hub install hub://guardrails/pii --quiet\n",
        "!guardrails hub install hub://guardrails/nsfw_text\n",
        "!guardrails hub install hub://guardrails/similar_to_document --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "dd1c6e5a-b167-43c1-bd27-bc5eb0764bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "dd1c6e5a-b167-43c1-bd27-bc5eb0764bdf",
        "outputId": "d414a866-003c-4655-fea1-76318af07d4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-01-22 17:15:29.186126: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-01-22 17:15:29.197246: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1737576929.211728    9378 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1737576929.215741    9378 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-22 17:15:29.230146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "[nltk_data] Downloading package stopwords to /home/levi/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from guardrails.validators import (register_validator, Validator, FailResult, ValidationResult, PassResult)\n",
        "from guardrails import Guard, OnFailAction\n",
        "from guardrails.hub import DetectPII\n",
        "from typing import Any, Dict, Optional, Callable, List\n",
        "\n",
        "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, RecognizerResult, Pattern\n",
        "import re\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "import unicodedata\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9319c2cc",
      "metadata": {
        "id": "9319c2cc"
      },
      "source": [
        "# Similaridade entre textos\n",
        "\n",
        "- Aqui encontra-se métodos de similaridade entre para verificar se o modelo está ou não alucinando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e59bd18b",
      "metadata": {
        "id": "e59bd18b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/levi/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Usando BERT para usar seus Embeddings\n",
        "\n",
        "if os.path.isdir(\"./bert_tokenizer\") and os.path.isdir(\"./bert_model\"):\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"./bert_tokenizer\")\n",
        "    model = BertModel.from_pretrained(\"./bert_model\")\n",
        "else:\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    tokenizer.save_pretrained(\"./bert_tokenizer\")\n",
        "    model.save_pretrained(\"./bert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b5cea0ee",
      "metadata": {
        "id": "b5cea0ee"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Descrição: Remove pontuação do texto\n",
        "\n",
        "    Args:\n",
        "        text: O texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Retorna o texto sem símbolos de pontuação\n",
        "\"\"\"\n",
        "def remove_pointing(text: str) -> str:\n",
        "    ans = \"\"\n",
        "    for c in text:\n",
        "          if unicodedata.category(c) != 'Po':\n",
        "               ans+=c\n",
        "    return ans\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição: Remove os acentos das palavras do texto\n",
        "\n",
        "    Args:\n",
        "        text: O texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Retorna o texto sem acentos\n",
        "\"\"\"\n",
        "def remove_accent(text: str) -> str:\n",
        "    nfkd = unicodedata.normalize('NFKD', text)\n",
        "    ans = \"\"\n",
        "    for c in nfkd:\n",
        "         if not unicodedata.combining(c):\n",
        "              ans += c\n",
        "    return ans\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição: Aplica lematização no texto\n",
        "\n",
        "    Args:\n",
        "        text: O texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Retorna o texto lematizado\n",
        "\"\"\"\n",
        "def lemmatize(text: str) -> str:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição: Remove as palavras irrelevantes do texto\n",
        "\n",
        "    Args:\n",
        "        words:  texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Lista de string sem as palavras irrelevantes\n",
        "\"\"\"\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    text_without_pointing_and_accent = remove_accent(remove_pointing(text))\n",
        "    lemmatized_text = lemmatize(text_without_pointing_and_accent)\n",
        "    words_splitted = lemmatized_text.split()\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    relevant_text = \"\"\n",
        "    for word in words_splitted:\n",
        "        if word.lower() not in stop_words and len(word) > 2 and len(word) < 15:\n",
        "            relevant_text += re.sub(r'[^a-zA-Z0-9]', '', word.lower()) + \" \"\n",
        "\n",
        "    return relevant_text\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Retorna os embeddings do texto passado como parâmetro da função.\n",
        "\n",
        "    Args:\n",
        "        text: texto usado para criar os embeddings\n",
        "\n",
        "    returns:\n",
        "        Retorna os Embeddings.\n",
        "\"\"\"\n",
        "def generate_embeddings(text: str) -> List[List]:\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    embeddings = outputs.last_hidden_state\n",
        "    sentence_embedding = embeddings.mean(dim=1)\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Calcula a similaridae cosseno entre dois trechos de textos.\n",
        "        Gera-se os embeddings para cada texto e em seguida, fazemos a similarida usando os embeddings.\n",
        "\n",
        "    args:\n",
        "        text1: texto usado para calcular a similaridade.\n",
        "        text1: texto usado para calcular a similaridade.\n",
        "\n",
        "    returns: Grau de similaridade em um intervalo fechado entre 0 (baixo) e 1 (alto).\n",
        "\"\"\"\n",
        "def cosine_similarity(text1: str, text2: str) -> float:\n",
        "    emb_text1 = generate_embeddings(text1)\n",
        "    emb_text2 = generate_embeddings(text2)\n",
        "\n",
        "    emb_text1 = emb_text1.cpu().numpy()\n",
        "    emb_text2 = emb_text2.cpu().numpy()\n",
        "\n",
        "    dot_product = np.dot(emb_text1, emb_text2.T)\n",
        "    text1Norm = np.linalg.norm(emb_text1)\n",
        "    text2Norm = np.linalg.norm(emb_text2)\n",
        "\n",
        "    return dot_product / (text1Norm * text2Norm)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Divide o texto em alguns pedaços de frases.\n",
        "\n",
        "    Args:\n",
        "        text: texto a ser dividido.\n",
        "        max_length: tamanho máximo de cada divisão.\n",
        "\n",
        "    returns: Lista de frases.\n",
        "\"\"\"\n",
        "def split_text(text, max_length: int = 10) -> List:\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    chunks = [tokenizer.convert_tokens_to_string(tokens[i:i + max_length]) for i in range(0, len(tokens), max_length)]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Calcula a similaridade entre dois textos.\n",
        "\n",
        "    Args:\n",
        "        text1: texto usado para calcular a similaridade.\n",
        "        text2: texto usado para calcular a similaridade.\n",
        "\n",
        "    returns:\n",
        "        Similaridade cosseno.\n",
        "\n",
        "\"\"\"\n",
        "def similarity_between_texts(text1, text2) -> float:\n",
        "\n",
        "    text1 = remove_stopwords(text1)\n",
        "    text2 = remove_stopwords(text2)\n",
        "\n",
        "    print(text1)\n",
        "    print(text2)\n",
        "\n",
        "    split_text1 = split_text(text1)\n",
        "    split_text2 = split_text(text2)\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    if len(split_text1) == 0 or len(split_text2) == 0:\n",
        "        return 0\n",
        "\n",
        "    for text1 in split_text1:\n",
        "        for text2 in split_text2:\n",
        "            similarities.append(cosine_similarity(text1, text2)[0][0])\n",
        "\n",
        "    media = np.mean(similarities)\n",
        "    print(media, similarities)\n",
        "    return media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dee83a34",
      "metadata": {
        "id": "dee83a34"
      },
      "outputs": [],
      "source": [
        "# Testes\n",
        "\n",
        "response_eureca = \"\"\"\n",
        "{\n",
        "    'sexo': {\n",
        "        'feminino': {\n",
        "            'quantidade': 194,\n",
        "            'estado_civil': {\n",
        "                'Casado': 2,\n",
        "                'Solteiro': 186,\n",
        "                'Divorciado': 1,\n",
        "                '-': 5\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 194,\n",
        "                'estrangeira': 0\n",
        "            },\n",
        "            'estados': {\n",
        "                'PE': 17,\n",
        "                'PB': 146,\n",
        "                'RJ': 4,\n",
        "                'RN': 4,\n",
        "                'CE': 3,\n",
        "                'SP': 7,\n",
        "                'MG': 1,\n",
        "                'MA': 2,\n",
        "                'AL': 1,\n",
        "                'PA': 1,\n",
        "                'BA': 1,\n",
        "                'PI': 2,\n",
        "                None: 5\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 18,\n",
        "                'idade_maxima': 39,\n",
        "                'media_idades': 22.47\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L1': 14,\n",
        "                'L6': 17,\n",
        "                '-': 59,\n",
        "                'L2': 26,\n",
        "                'L5': 13,\n",
        "                'L13': 1,\n",
        "                'L14': 1,\n",
        "                'Bon. estadual': 41,\n",
        "                'L9': 1,\n",
        "                'LB_PPI': 10,\n",
        "                'LI_PPI': 6,\n",
        "                'LB_EP': 2,\n",
        "                'LI_PCD': 3\n",
        "            },\n",
        "            'cor': {\n",
        "                'Branca': 98,\n",
        "                'Parda': 87,\n",
        "                'Preta': 4,\n",
        "                'Não declarada': 5\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 7.62},\n",
        "                'tipo_de_ensino_medio': {\n",
        "                    'Somente escola pública': 97,\n",
        "                    'Somente escola privada': 96,\n",
        "                    'Pública e privada, tendo ficado mais tempo em escola privada': 1\n",
        "                }\n",
        "            },\n",
        "\n",
        "        'masculino': {\n",
        "            'quantidade': 709,\n",
        "            'estado_civil': {\n",
        "                'Solteiro': 685,\n",
        "                'Casado': 6,\n",
        "                '-': 17,\n",
        "                'Divorciado': 1\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 708,\n",
        "                'estrangeira': 1\n",
        "            },\n",
        "            'estados': {\n",
        "                'PB': 528,\n",
        "                None: 21,\n",
        "                'SP': 24,\n",
        "                'PE': 49,\n",
        "                'RJ': 22,\n",
        "                'CE': 15,\n",
        "                'RN': 13,\n",
        "                'DF': 2,\n",
        "                'TO': 1,\n",
        "                'AL': 3,\n",
        "                'BA': 14,\n",
        "                'MA': 4,\n",
        "                'PR': 1,\n",
        "                'MS': 1,\n",
        "                'PA': 2,\n",
        "                'MG': 3,\n",
        "                'PI': 4,\n",
        "                'AP': 1,\n",
        "                'RO': 1\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 17,\n",
        "                'idade_maxima': 44,\n",
        "                'media_idades': 22.79\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L2': 78,\n",
        "                '-': 250,\n",
        "                'L1': 51,\n",
        "                'L6': 68,\n",
        "                'L5': 56,\n",
        "                'L10': 3,\n",
        "                'L13': 3,\n",
        "                'L9': 3,\n",
        "                'Bon. estadual': 129,\n",
        "                'L14': 1,\n",
        "                'LI_PPI': 22,\n",
        "                'LB_PPI': 22,\n",
        "                'LB_PCD': 5,\n",
        "                'LI_EP': 9,\n",
        "                'LB_EP': 7,\n",
        "                'LI_PCD': 2\n",
        "            },\n",
        "            'cor': {\n",
        "                'Parda': 291,\n",
        "                'Branca': 360,\n",
        "                'Preta': 33,\n",
        "                'Amarela': 7,\n",
        "                'Indígena': 1,\n",
        "                'Não declarada': 17\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 6.79\n",
        "            },\n",
        "            'tipo_de_ensino_medio': {\n",
        "                'Somente escola pública': 347,\n",
        "                'Somente escola privada': 359,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola pública': 1,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola privada': 2\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "response_llm = \"\"\"\n",
        "        ### Alunas (Feminino)\n",
        "\n",
        "        - **Quantidade Total**: 183\n",
        "        - **Estado Civil**\n",
        "        - Solteiro: 175\n",
        "        - Casado:3\n",
        "        - **Nacionalidade**: 100% Brasileira\n",
        "        - **Principais Estados**\n",
        "        -PB:139\n",
        "        - PE:17\n",
        "        - **Idade**:\n",
        "        - Média: 21.68 anos\n",
        "        - Mínima: 17 anos\n",
        "        - Máxima: 39 anos\n",
        "        - **Política Afirmativa**:\n",
        "        - Bon. estadual: 40\n",
        "        - L2: 26\n",
        "        - **Cor/Raça**:\n",
        "          -Branca: 92\n",
        "          -Parda: 83\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 6.78\n",
        "        - **Tipo de Ensino Médio**\n",
        "        - Somente escola pública: 93\n",
        "        - Somente escola privada:89\n",
        "\n",
        "        ### Alunos (Masculino)\n",
        "\n",
        "        ⁃ **Quantidade Total**: 658\n",
        "        - **Estado Civil**:\n",
        "        ⁃ Solteiro: 641\n",
        "        - Casado:6\n",
        "        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\n",
        "        - **Principais Estados**:\n",
        "        -PB:498\n",
        "        -PE: 47\n",
        "        ⁃ **Idade**:\n",
        "        ⁃ Média: 21.87 anos\n",
        "        - Minima: 17 anos\n",
        "        ⁃ Máxima: 43 anos\n",
        "        - **Política Afirmativa**\n",
        "        - Bon. estadual: 127\n",
        "        - L2:71\n",
        "        - **Cor/Raca**:\n",
        "        ⁃ Branca: 337\n",
        "        -Parda: 271\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 7.05\n",
        "        - **Tipo de Ensino Médio**:\n",
        "        ⁃ Somente escola pública: 329\n",
        "        - Somente escola privada: 327\n",
        "\n",
        "        Essas informações destacam a distribuição de gênero, origem\n",
        "        geográfica, política afirmativa, e outros aspectos demograficos e\n",
        "        educacionais dos alunos.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946741fc",
      "metadata": {
        "id": "946741fc"
      },
      "source": [
        "# Guardrails\n",
        "\n",
        "- Guardrails é uma estrutura Python que ajuda a construir aplicativos de IA confiáveis, executando duas funções principais:\n",
        "\n",
        "- Guardrails executa protetores de entrada/saída em sua aplicação que detectam, quantificam e mitigam a presença de tipos específicos de riscos. Para ver o conjunto completo de riscos, confira Guardrails Hub.\n",
        "- Guardrails ajudam você a gerar dados estruturados de LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d60d85db",
      "metadata": {
        "id": "d60d85db"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Descrição:\n",
        "        Calcula a similaridade entre dois textos e valida se a similaridade está acima de um limiar definido pelo usuário.\n",
        "\n",
        "    Returns:\n",
        "        Retorna a similaridade entre dois textos.\n",
        "\"\"\"\n",
        "@register_validator(name=\"guardrails/teste\", data_type=\"string\")\n",
        "class ValidadorDeSimilaridade(Validator):\n",
        "    def __init__(self, texto1: str, texto2: str, match_type: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
        "        super().__init__(on_fail=on_fail, match_type=match_type)\n",
        "\n",
        "        self.texto1 = texto1\n",
        "        self.texto2 = texto2\n",
        "\n",
        "    def validate(self, value: Any, metadata: Dict = {}) -> ValidationResult:\n",
        "        similarity = float(f\"{similarity_between_texts(self.texto1, self.texto2):.1f}\")\n",
        "        print(similarity)\n",
        "\n",
        "        ideal_similarity = 0.7\n",
        "        if similarity < ideal_similarity:\n",
        "            print(f\"{value}: Similaridade baixa {similarity} (menor que {ideal_similarity})\")\n",
        "            return FailResult(error_message=\"Erro\")\n",
        "\n",
        "        print(f\"{value}: Similaridade alta de {similarity} (igual ou acima de {ideal_similarity})\")\n",
        "        return PassResult()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d02db314",
      "metadata": {
        "id": "d02db314"
      },
      "outputs": [],
      "source": [
        "def teste(texto1, texto2):\n",
        "    guard = Guard().use(\n",
        "        ValidadorDeSimilaridade(texto1=texto1, texto2=texto2)\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        guard.parse(\"Agente Inteligente\").model_validate\n",
        "        print(\"Passou no teste de similaridade cosseno!\")\n",
        "    except Exception as e:\n",
        "        print(\"Ocorreu um erro: \", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dbfeb964",
      "metadata": {
        "id": "dbfeb964"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/levi/.local/lib/python3.10/site-packages/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lula \n",
            "carro \n",
            "0.7625983 [0.7625983]\n",
            "0.8\n",
            "Agente Inteligente: Similaridade alta de 0.8 (igual ou acima de 0.7)\n",
            "Passou no teste de similaridade cosseno!\n"
          ]
        }
      ],
      "source": [
        "texto1 = \"\"\"\n",
        "lula\n",
        "\"\"\"\n",
        "\n",
        "texto2 = \"\"\"\n",
        "carro\n",
        "\"\"\"\n",
        "\n",
        "teste(texto1=texto1, texto2=texto2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ed11eb54",
      "metadata": {
        "id": "ed11eb54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "onde sao aluno ciencia computacao liste todo estado \n",
            "aluno ciencia computacao vir diverso estado incluir pernambuco rio janeiro sao paulo minas gerais bahia sao algum exemplo estado origem aluno \n",
            "0.659812 [0.8117717, 0.74846905, 0.5817227, 0.6511542, 0.5596056, 0.6946472, 0.6640316, 0.5304727, 0.8176472, 0.5385981]\n",
            "0.7\n",
            "Agente Inteligente: Similaridade alta de 0.7 (igual ou acima de 0.7)\n",
            "Passou no teste de similaridade cosseno!\n"
          ]
        }
      ],
      "source": [
        "texto1 = \"\"\"\n",
        "de onde sao os alunos de ciencia da computacao? liste todos os estados\n",
        "\"\"\"\n",
        "\n",
        "texto2 = \"\"\"\n",
        "Os alunos de Ciência da Computação vêm de diversos estados,\n",
        "incluindo:\n",
        "\n",
        "\n",
        "Pernambuco (PE)\n",
        "Rio de Janeiro (RJ)\n",
        "São Paulo (SP)\n",
        "Minas Gerais (MG)\n",
        "Bahia (BA)\n",
        "\n",
        "\n",
        "Esses sao alguns exemplos dos estados de origem dos alunos.\"\"\"\n",
        "\n",
        "teste(texto1=texto1, texto2=texto2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8c60d1",
      "metadata": {
        "id": "8b8c60d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2a4f50c8",
      "metadata": {
        "id": "2a4f50c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lula presidente brasil \n",
            "lula nao presidente brasil \n",
            "0.9101971 [0.9101971]\n",
            "0.9\n",
            "Agente Inteligente: Similaridade alta de 0.9 (igual ou acima de 0.7)\n",
            "Passou no teste de similaridade cosseno!\n"
          ]
        }
      ],
      "source": [
        "texto1 = \"Lula é o presidente do Brasil\"\n",
        "texto2 = \"Lula não é o presidente do Brasil\"\n",
        "\n",
        "teste(texto1=texto1, texto2=texto2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "07ba3384",
      "metadata": {
        "id": "07ba3384"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Descrição:\n",
        "        A partir de um texto passado através do método parse, este guardrail camufla a matricula do usuário no texto e retorna o texto camuflado.\n",
        "\"\"\"\n",
        "@register_validator(name=\"guardrails/enrollment\", data_type=\"string\")\n",
        "class PIIValidator(Validator):\n",
        "    def __init__(self, on_match: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
        "        super().__init__(on_match=on_match, on_fail=on_fail)\n",
        "\n",
        "    def validate(self, value: str, metadata: Dict = {}) -> ValidationResult:\n",
        "        year = str(dt.datetime.now().year)[2:]\n",
        "\n",
        "        enrollment = r\"\\b\\d{1}[1-\" + year[0] + r\"]\" + r\"[0-\" + year[1] + r\"]\" + r\"[12]\\d{5}\\b\"\n",
        "        enrollment_pattern = Pattern(name=\"Enrollment_Pattern\", regex=enrollment, score=0.6)\n",
        "\n",
        "        enrollment_recognizer = PatternRecognizer(name=\"MATRICULA\", patterns=[enrollment_pattern], supported_entity=\"Enrollment_Pattern\", supported_language=\"en\")\n",
        "\n",
        "        analyzer = AnalyzerEngine()\n",
        "        analyzer.registry.add_recognizer(enrollment_recognizer)\n",
        "\n",
        "        results = analyzer.analyze(text=value, entities=[\"Enrollment_Pattern\"], language=\"en\")\n",
        "\n",
        "        if results:\n",
        "            for result in results:\n",
        "                start, end = result.start, result.end\n",
        "                value = value[:start] + \"<MATRICULA>\" + value[end:]\n",
        "            return FailResult(error_message=value)\n",
        "\n",
        "        return PassResult()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "185b98f9",
      "metadata": {
        "id": "185b98f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
            "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation failed for field with errors: A minha matricula é o seguinte: <MATRICULA>, busque informaões sobre ela\n"
          ]
        }
      ],
      "source": [
        "guardas_eureca = Guard().use(PIIValidator)\n",
        "\n",
        "try:\n",
        "    guardas_eureca.parse(\"A minha matricula é o seguinte: 221199999, busque informaões sobre ela\").model_validate\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3185903b",
      "metadata": {
        "id": "3185903b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Descrição:\n",
        "    Guardrail para dado um texto, camuflar o seu CPF.\n",
        "\"\"\"\n",
        "@register_validator(name=\"guardrails/cpf\", data_type=\"string\")\n",
        "class PIIValidatorCPF(Validator):\n",
        "    def __init__(self, on_match: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
        "        super().__init__(on_match=on_match, on_fail=on_fail)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Descrição:\n",
        "        Verifica se a possivel sequência de números é ou não um CPF através do calculo dos digitos verificadores dos 9 primeiros números.\n",
        "\n",
        "    Args:\n",
        "        cpf_user: CPF a ser validado.\n",
        "\n",
        "    returns:\n",
        "        Retorna um valor booleano.\n",
        "        True se a sequência de números é um CPF e False, caso contrário.\n",
        "    \"\"\"\n",
        "    def validate_digit_verificator(self, cpf_user):\n",
        "        if len(set(cpf_user)) == 1: return False\n",
        "\n",
        "        cpf = cpf_user[:9]\n",
        "        sum = 0\n",
        "        for i in range(1, len(cpf) + 1):\n",
        "            sum += i * int(cpf[i - 1])\n",
        "        first_digit_verificator = sum % 11\n",
        "\n",
        "        if first_digit_verificator == 10:\n",
        "            first_digit_verificator = 0\n",
        "\n",
        "\n",
        "        sum = 0\n",
        "        cpf = cpf + str(first_digit_verificator)\n",
        "        for i in range(len(cpf)):\n",
        "            sum += i * int(cpf[i])\n",
        "        second_digit_verificator = sum % 11\n",
        "\n",
        "        if second_digit_verificator == 10:\n",
        "            second_digit_verificator = 0\n",
        "\n",
        "        cpf = cpf[:9] + str(first_digit_verificator) + str(second_digit_verificator)\n",
        "        return cpf == cpf_user\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Descrição:\n",
        "        Camufla o CPF de um texto, buscando as posições onde os possiveis CPFs ocorrem.\n",
        "\n",
        "    Args:\n",
        "        text: string do cpf a ser validado.\n",
        "\n",
        "    returns:\n",
        "        Retorna um texto com o CPF camuflado.\n",
        "    \"\"\"\n",
        "    def replace_valid_cpfs(self, text) -> str:\n",
        "        cpf_pattern =r\"\\b\\d{3}[^a-zA-Z]*\\d{3}[^a-zA-Z]*\\d{3}[^a-zA-Z]*\\d{2}\\b\"\n",
        "\n",
        "        def validate_and_replace(match):\n",
        "            cpf = match.group(0)\n",
        "            cpf_numbers = re.sub(r\"[^\\d]\", \"\", cpf)\n",
        "\n",
        "            if self.validate_digit_verificator(cpf_numbers):\n",
        "                return \"<CPF>\"\n",
        "            return cpf\n",
        "\n",
        "        return re.sub(cpf_pattern, validate_and_replace, text)\n",
        "\n",
        "    def validate(self, value: str, metadata: Dict = {}) -> ValidationResult:\n",
        "        result = self.replace_valid_cpfs(value)\n",
        "\n",
        "        if \"<CPF>\" in result:\n",
        "            return FailResult(error_message=result)\n",
        "        return PassResult()\n",
        "\n",
        "\n",
        "guardas_eureca = Guard().use(PIIValidatorCPF)\n",
        "\n",
        "try:\n",
        "    result = guardas_eureca.parse(\"O meu CPF é o seguinte: 99999999999, busque informaões sobre ele\").model_validate\n",
        "except Exception as e:\n",
        "    print(str(e)[41:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "cadd8f4c",
      "metadata": {
        "id": "cadd8f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Meus emails são <EMAIL_ADDRESS> ou <EMAIL_ADDRESS> ou <EMAIL_ADDRESS> e <EMAIL_ADDRESS>;\n",
            "e os meus números de telefones são esses <PHONE_NUMBER> ou <PHONE_NUMBER> ou <PHONE_NUMBER> e <PHONE_NUMBER>,\n",
            "busque no <URL> ou <URL>.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "guarda_email = Guard().use(DetectPII(pii_entities=\"pii\", on_fail=\"fix\"))\n",
        "\n",
        "text = \"\"\"\n",
        "Meus emails são demo@lol.com ou dominio@gmail.com ou dominio@hotmail.com e dominio@hotmail.com.br;\n",
        "e os meus números de telefones são esses (99) 999999999 ou (99)999999999 ou 99999999999 e 99999999999,\n",
        "busque no google.com.br ou uol.com.\n",
        "\"\"\"\n",
        "output = guarda_email.parse(\n",
        "    llm_output=text,\n",
        "    metadata={\"pii_entities\": [\"EMAIL_ADDRESS\", \"URL\", \"PHONE_NUMBER\"]},\n",
        ")\n",
        "\n",
        "print(output.validated_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "08e9ecaa",
      "metadata": {
        "id": "08e9ecaa"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Valida se a LLM alucinou baseado na saída da LLM e os dados do Eureca.\n",
        "\"\"\"\n",
        "@register_validator(name=\"hallucination_detector\", data_type=\"string\")\n",
        "class HallucinationValidation(Validator):\n",
        "    def __init__(\n",
        "            self,\n",
        "            embedding_model: Optional[str] = None,\n",
        "            entailment_model: Optional[str] = None,\n",
        "            sources: Optional[List[str]] = None,\n",
        "            **kwargs\n",
        "        ):\n",
        "        if embedding_model is None:\n",
        "            embedding_model = 'all-MiniLM-L6-v2'\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "\n",
        "        self.sources = sources\n",
        "\n",
        "        if entailment_model is None:\n",
        "            entailment_model = 'GuardrailsAI/finetuned_nli_provenance'\n",
        "        self.nli_pipeline = pipeline(\"text-classification\", model=entailment_model)\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def validate(\n",
        "        self, value: str, metadata: Optional[Dict[str, str]] = None\n",
        "    ) -> ValidationResult:\n",
        "        sentences = self.split_sentences(value)\n",
        "\n",
        "        relevant_sources = self.find_relevant_sources(sentences, self.sources)\n",
        "\n",
        "        entailed_sentences = []\n",
        "        hallucinated_sentences = []\n",
        "        for sentence in sentences:\n",
        "            is_entailed = self.check_entailment(sentence, relevant_sources)\n",
        "            if not is_entailed:\n",
        "                hallucinated_sentences.append(sentence)\n",
        "            else:\n",
        "                entailed_sentences.append(sentence)\n",
        "\n",
        "        if len(hallucinated_sentences) > 0:\n",
        "            return FailResult(\n",
        "                error_message=f\"Alucinação detectada: {hallucinated_sentences}\",\n",
        "            )\n",
        "\n",
        "        return PassResult()\n",
        "\n",
        "    def split_sentences(self, text: str) -> List[str]:\n",
        "        return nltk.sent_tokenize(text)\n",
        "\n",
        "    def find_relevant_sources(self, sentences: str, sources: List[str]) -> List[str]:\n",
        "        source_embeds = self.embedding_model.encode(sources)\n",
        "        sentence_embeds = self.embedding_model.encode(sentences)\n",
        "\n",
        "        relevant_sources = []\n",
        "\n",
        "        for sentence_idx in range(len(sentences)):\n",
        "            sentence_embed = sentence_embeds[sentence_idx, :].reshape(1, -1)\n",
        "            cos_similarities = np.sum(np.multiply(source_embeds, sentence_embed), axis=1)\n",
        "            top_sources = np.argsort(cos_similarities)[::-1][:5]\n",
        "            top_sources = [i for i in top_sources if cos_similarities[i] > 0.8]\n",
        "\n",
        "            relevant_sources.extend([sources[i] for i in top_sources])\n",
        "\n",
        "        return relevant_sources\n",
        "\n",
        "    def check_entailment(self, sentence: str, sources: List[str]) -> bool:\n",
        "        for source in sources:\n",
        "            output = self.nli_pipeline({'text': source, 'text_pair': sentence})\n",
        "            if output['label'] == 'entailment':\n",
        "                return True\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e6041145",
      "metadata": {
        "id": "e6041145"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at GuardrailsAI/finetuned_nli_provenance and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo salvo em: ./saved_models/finetuned_nli_provenance\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"GuardrailsAI/finetuned_nli_provenance\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "save_directory = \"./saved_models/finetuned_nli_provenance\"\n",
        "\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Modelo salvo em: {save_directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "1c230b65",
      "metadata": {
        "id": "1c230b65"
      },
      "outputs": [],
      "source": [
        "save_directory = \"./saved_models/finetuned_nli_provenance\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "model = AutoModel.from_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ef2b3d2a",
      "metadata": {
        "id": "ef2b3d2a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/levi/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./saved_models/finetuned_nli_provenance and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "Validation failed for field with errors: Alucinação detectada: ['\\n        ### Alunas (Feminino)\\n\\n        - **Quantidade Total**: 183\\n        - **Estado Civil**\\n        - Solteiro: 175\\n        - Casado:3\\n        - **Nacionalidade**: 100% Brasileira\\n        - **Principais Estados**\\n        -PB:139\\n        - PE:17\\n        - **Idade**:\\n        - Média: 21.68 anos\\n        - Mínima: 17 anos\\n        - Máxima: 39 anos\\n        - **Política Afirmativa**:\\n        - Bon.', 'estadual: 40\\n        - L2: 26\\n        - **Cor/Raça**:\\n          -Branca: 92\\n          -Parda: 83\\n        - **Renda Per Capita**:\\n        - Média: 6.78\\n        - **Tipo de Ensino Médio**\\n        - Somente escola pública: 93\\n        - Somente escola privada:89\\n\\n        ### Alunos (Masculino)\\n\\n        ⁃ **Quantidade Total**: 658\\n        - **Estado Civil**:\\n        ⁃ Solteiro: 641\\n        - Casado:6\\n        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\\n        - **Principais Estados**:\\n        -PB:498\\n        -PE: 47\\n        ⁃ **Idade**:\\n        ⁃ Média: 21.87 anos\\n        - Minima: 17 anos\\n        ⁃ Máxima: 43 anos\\n        - **Política Afirmativa**\\n        - Bon.', 'estadual: 127\\n        - L2:71\\n        - **Cor/Raca**:\\n        ⁃ Branca: 337\\n        -Parda: 271\\n        - **Renda Per Capita**:\\n        - Média: 7.05\\n        - **Tipo de Ensino Médio**:\\n        ⁃ Somente escola pública: 329\\n        - Somente escola privada: 327\\n\\n        Essas informações destacam a distribuição de gênero, origem\\n        geográfica, política afirmativa, e outros aspectos demograficos e\\n        educacionais dos alunos.']",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m guard \u001b[38;5;241m=\u001b[39m Guard()\u001b[38;5;241m.\u001b[39muse(\n\u001b[1;32m      2\u001b[0m     HallucinationValidation(\n\u001b[1;32m      3\u001b[0m         embedding_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m---> 10\u001b[0m \u001b[43mguard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_llm\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/hub_telemetry/hub_tracing.py:144\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m origin\n\u001b[1;32m    142\u001b[0m origin \u001b[38;5;241m=\u001b[39m origin \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m--> 144\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m add_attributes(\n\u001b[1;32m    146\u001b[0m     span, attrs, name, origin, \u001b[38;5;241m*\u001b[39margs, response\u001b[38;5;241m=\u001b[39mresp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/guard.py:1090\u001b[0m, in \u001b[0;36mGuard.validate\u001b[0;34m(self, llm_output, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;129m@trace\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/guard_call\u001b[39m\u001b[38;5;124m\"\u001b[39m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGuard.validate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m, llm_output: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ValidationOutcome[OT]:\n\u001b[0;32m-> 1090\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/hub_telemetry/hub_tracing.py:144\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m origin\n\u001b[1;32m    142\u001b[0m origin \u001b[38;5;241m=\u001b[39m origin \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m--> 144\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m add_attributes(\n\u001b[1;32m    146\u001b[0m     span, attrs, name, origin, \u001b[38;5;241m*\u001b[39margs, response\u001b[38;5;241m=\u001b[39mresp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/guard.py:966\u001b[0m, in \u001b[0;36mGuard.parse\u001b[0;34m(self, llm_output, metadata, llm_api, num_reasks, prompt_params, full_schema_reask, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m default_messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_opts\u001b[38;5;241m.\u001b[39mmessages \u001b[38;5;28;01mif\u001b[39;00m llm_api \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    964\u001b[0m messages \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_messages)\n\u001b[0;32m--> 966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_guard_execution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore # streams are supported for parse\u001b[39;49;00m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_reasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_num_reasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_schema_reask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_schema_reask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/telemetry/guard_tracing.py:195\u001b[0m, in \u001b[0;36mtrace_guard_execution\u001b[0;34m(guard_name, history, _execute_fn, tracer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m             guard_span\u001b[38;5;241m.\u001b[39mset_status(status\u001b[38;5;241m=\u001b[39mStatusCode\u001b[38;5;241m.\u001b[39mERROR, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m--> 195\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _execute_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/telemetry/guard_tracing.py:184\u001b[0m, in \u001b[0;36mtrace_guard_execution\u001b[0;34m(guard_name, history, _execute_fn, tracer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m guard_span\u001b[38;5;241m.\u001b[39mset_attribute(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguard.name\u001b[39m\u001b[38;5;124m\"\u001b[39m, guard_name)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 184\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Iterator) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    186\u001b[0m         result, ValidationOutcome\n\u001b[1;32m    187\u001b[0m     ):\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trace_stream_guard(guard_span, result, history)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/guard.py:792\u001b[0m, in \u001b[0;36mGuard._execute\u001b[0;34m(self, llm_api, llm_output, prompt_params, num_reasks, messages, reask_messages, metadata, full_schema_reask, *args, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m current_otel_context \u001b[38;5;241m=\u001b[39m otel_context\u001b[38;5;241m.\u001b[39mget_current()\n\u001b[1;32m    790\u001b[0m wrapped__exec \u001b[38;5;241m=\u001b[39m wrap_with_otel_context(current_otel_context, __exec)\n\u001b[0;32m--> 792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mguard_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrapped__exec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_reasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_reasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_schema_reask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_schema_reask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/telemetry/common.py:100\u001b[0m, in \u001b[0;36mwrap_with_otel_context.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m token \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mattach(outer_scope_otel_context)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Execute 'func' within the attached context\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Ensure the context is detached after execution\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m#   to maintain correct context management\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     context\u001b[38;5;241m.\u001b[39mdetach(token)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/guard.py:771\u001b[0m, in \u001b[0;36mGuard._execute.<locals>.__exec\u001b[0;34m(self, llm_api, llm_output, prompt_params, num_reasks, messages, metadata, full_schema_reask, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mpush(call_log)\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Otherwise, call the LLM synchronously\u001b[39;00m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mllm_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_reasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_reasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_schema_reask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_schema_reask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcall_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcall_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/guard.py:870\u001b[0m, in \u001b[0;36mGuard._exec\u001b[0;34m(self, llm_api, llm_output, call_log, prompt_params, num_reasks, metadata, full_schema_reask, messages, *args, **kwargs)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# Otherwise, use Runner\u001b[39;00m\n\u001b[1;32m    852\u001b[0m     runner \u001b[38;5;241m=\u001b[39m Runner(\n\u001b[1;32m    853\u001b[0m         output_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_type,\n\u001b[1;32m    854\u001b[0m         output_schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_schema\u001b[38;5;241m.\u001b[39mto_dict(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    868\u001b[0m         exec_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_opts,\n\u001b[1;32m    869\u001b[0m     )\n\u001b[0;32m--> 870\u001b[0m     call \u001b[38;5;241m=\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcall_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ValidationOutcome[OT]\u001b[38;5;241m.\u001b[39mfrom_guard_history(call)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/hub_telemetry/hub_tracing.py:144\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m origin\n\u001b[1;32m    142\u001b[0m origin \u001b[38;5;241m=\u001b[39m origin \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m--> 144\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m add_attributes(\n\u001b[1;32m    146\u001b[0m     span, attrs, name, origin, \u001b[38;5;241m*\u001b[39margs, response\u001b[38;5;241m=\u001b[39mresp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/run/runner.py:200\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, call_log, prompt_params)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# Because Pydantic v1 doesn't respect property setters\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     call_log\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_log\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/run/runner.py:170\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, call_log, prompt_params)\u001b[0m\n\u001b[1;32m    167\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_reasks \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# Run a single step.\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcall_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcall_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# Loop again?\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_loop(index, iteration\u001b[38;5;241m.\u001b[39mreasks):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/hub_telemetry/hub_tracing.py:144\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m origin\n\u001b[1;32m    142\u001b[0m origin \u001b[38;5;241m=\u001b[39m origin \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m--> 144\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m add_attributes(\n\u001b[1;32m    146\u001b[0m     span, attrs, name, origin, \u001b[38;5;241m*\u001b[39margs, response\u001b[38;5;241m=\u001b[39mresp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/telemetry/runner_tracing.py:85\u001b[0m, in \u001b[0;36mtrace_step.<locals>.trace_step_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m             add_step_attributes(step_span, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     84\u001b[0m             add_user_attributes(step_span)\n\u001b[0;32m---> 85\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/telemetry/runner_tracing.py:77\u001b[0m, in \u001b[0;36mtrace_step.<locals>.trace_step_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracer\u001b[38;5;241m.\u001b[39mstart_as_current_span(\n\u001b[1;32m     73\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     context\u001b[38;5;241m=\u001b[39mcurrent_otel_context,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     75\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m step_span:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m         add_step_attributes(step_span, response, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     79\u001b[0m         add_user_attributes(step_span)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/run/runner.py:284\u001b[0m, in \u001b[0;36mRunner.step\u001b[0;34m(self, index, output_schema, call_log, api, messages, prompt_params, output)\u001b[0m\n\u001b[1;32m    282\u001b[0m     iteration\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39merror \u001b[38;5;241m=\u001b[39m error_message\n\u001b[1;32m    283\u001b[0m     iteration\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;241m=\u001b[39m e\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m iteration\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/run/runner.py:269\u001b[0m, in \u001b[0;36mRunner.step\u001b[0;34m(self, index, output_schema, call_log, api, messages, prompt_params, output)\u001b[0m\n\u001b[1;32m    266\u001b[0m     reasks, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintrospect(parsed_output)\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;66;03m# Validate: run output validation.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     validated_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparsed_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_schema\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     iteration\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mvalidation_response \u001b[38;5;241m=\u001b[39m validated_output\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;66;03m# Introspect: inspect validated output for reasks.\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/hub_telemetry/hub_tracing.py:144\u001b[0m, in \u001b[0;36mtrace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m origin\n\u001b[1;32m    142\u001b[0m origin \u001b[38;5;241m=\u001b[39m origin \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m name\n\u001b[0;32m--> 144\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m add_attributes(\n\u001b[1;32m    146\u001b[0m     span, attrs, name, origin, \u001b[38;5;241m*\u001b[39margs, response\u001b[38;5;241m=\u001b[39mresp, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/run/runner.py:465\u001b[0m, in \u001b[0;36mRunner.validate\u001b[0;34m(self, iteration, attempt_number, parsed_output, output_schema, stream, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_type \u001b[38;5;241m!=\u001b[39m OutputTypes\u001b[38;5;241m.\u001b[39mSTRING:\n\u001b[1;32m    463\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m validated_output, metadata \u001b[38;5;241m=\u001b[39m \u001b[43mvalidator_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidator_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tracer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disable_tracer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m$\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mupdate(metadata)\n\u001b[1;32m    476\u001b[0m validated_output \u001b[38;5;241m=\u001b[39m validator_service\u001b[38;5;241m.\u001b[39mpost_process_validation(\n\u001b[1;32m    477\u001b[0m     validated_output, attempt_number, iteration, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_type\n\u001b[1;32m    478\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/validator_service/__init__.py:91\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(value, metadata, validator_map, iteration, disable_tracer, path, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not obtain an event loop.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Falling back to synchronous validation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m         )\n\u001b[1;32m     89\u001b[0m         validator_service \u001b[38;5;241m=\u001b[39m SequentialValidatorService(disable_tracer)\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidator_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidator_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore It exists when we need it to.\u001b[39;49;00m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/validator_service/sequential_validator_service.py:459\u001b[0m, in \u001b[0;36mSequentialValidatorService.validate\u001b[0;34m(self, value, metadata, validator_map, iteration, absolute_path, reference_path, stream, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m         value[key] \u001b[38;5;241m=\u001b[39m child_value\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Then validate the parent value\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m value, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_validators\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidator_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mabsolute_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value, metadata\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/validator_service/sequential_validator_service.py:379\u001b[0m, in \u001b[0;36mSequentialValidatorService.run_validators\u001b[0;34m(self, iteration, validator_map, value, metadata, absolute_property_path, reference_property_path, stream, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         fixed_value \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mfix_value\n\u001b[1;32m    371\u001b[0m         rechecked_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_validator_sync(\n\u001b[1;32m    372\u001b[0m             validator,\n\u001b[1;32m    373\u001b[0m             fixed_value,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    378\u001b[0m         )\n\u001b[0;32m--> 379\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_correction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrechecked_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrechecked_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, PassResult):\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    387\u001b[0m         validator\u001b[38;5;241m.\u001b[39moverride_value_on_pass\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mvalue_override \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39mValueOverrideSentinel\n\u001b[1;32m    389\u001b[0m     ):\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/guardrails/validator_service/validator_service_base.py:106\u001b[0m, in \u001b[0;36mValidatorServiceBase.perform_correction\u001b[0;34m(self, result, value, validator, rechecked_value)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FieldReAsk(\n\u001b[1;32m    102\u001b[0m         incorrect_value\u001b[38;5;241m=\u001b[39mvalue,\n\u001b[1;32m    103\u001b[0m         fail_results\u001b[38;5;241m=\u001b[39m[result],\n\u001b[1;32m    104\u001b[0m     )\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_fail_descriptor \u001b[38;5;241m==\u001b[39m OnFailAction\u001b[38;5;241m.\u001b[39mEXCEPTION:\n\u001b[0;32m--> 106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation failed for field with errors: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([result\u001b[38;5;241m.\u001b[39merror_message])\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_fail_descriptor \u001b[38;5;241m==\u001b[39m OnFailAction\u001b[38;5;241m.\u001b[39mFILTER:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Filter()\n",
            "\u001b[0;31mValidationError\u001b[0m: Validation failed for field with errors: Alucinação detectada: ['\\n        ### Alunas (Feminino)\\n\\n        - **Quantidade Total**: 183\\n        - **Estado Civil**\\n        - Solteiro: 175\\n        - Casado:3\\n        - **Nacionalidade**: 100% Brasileira\\n        - **Principais Estados**\\n        -PB:139\\n        - PE:17\\n        - **Idade**:\\n        - Média: 21.68 anos\\n        - Mínima: 17 anos\\n        - Máxima: 39 anos\\n        - **Política Afirmativa**:\\n        - Bon.', 'estadual: 40\\n        - L2: 26\\n        - **Cor/Raça**:\\n          -Branca: 92\\n          -Parda: 83\\n        - **Renda Per Capita**:\\n        - Média: 6.78\\n        - **Tipo de Ensino Médio**\\n        - Somente escola pública: 93\\n        - Somente escola privada:89\\n\\n        ### Alunos (Masculino)\\n\\n        ⁃ **Quantidade Total**: 658\\n        - **Estado Civil**:\\n        ⁃ Solteiro: 641\\n        - Casado:6\\n        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\\n        - **Principais Estados**:\\n        -PB:498\\n        -PE: 47\\n        ⁃ **Idade**:\\n        ⁃ Média: 21.87 anos\\n        - Minima: 17 anos\\n        ⁃ Máxima: 43 anos\\n        - **Política Afirmativa**\\n        - Bon.', 'estadual: 127\\n        - L2:71\\n        - **Cor/Raca**:\\n        ⁃ Branca: 337\\n        -Parda: 271\\n        - **Renda Per Capita**:\\n        - Média: 7.05\\n        - **Tipo de Ensino Médio**:\\n        ⁃ Somente escola pública: 329\\n        - Somente escola privada: 327\\n\\n        Essas informações destacam a distribuição de gênero, origem\\n        geográfica, política afirmativa, e outros aspectos demograficos e\\n        educacionais dos alunos.']"
          ]
        }
      ],
      "source": [
        "guard = Guard().use(\n",
        "    HallucinationValidation(\n",
        "        embedding_model='all-MiniLM-L6-v2',\n",
        "        entailment_model='./saved_models/finetuned_nli_provenance',\n",
        "        sources=[response_eureca],\n",
        "        on_fail=OnFailAction.EXCEPTION\n",
        "    )\n",
        ")\n",
        "\n",
        "guard.validate(response_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8520a0d",
      "metadata": {
        "id": "f8520a0d"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "CLASSIFIER = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model='facebook/bart-large-mnli',\n",
        "    hypothesis_template=\"Verifique em qual tópico o texto acima melhor se adequa: {}.\",\n",
        "    multi_label=True,\n",
        ")\n",
        "\n",
        "dataset = [\n",
        "    (\"Quais são as disciplinas oferecidas no curso de Matemática\", \"disciplina\"),\n",
        "    (\"Quantos cursos a universidade oferece\", \"curso\"),\n",
        "    (\"Qual o calendário acadêmico deste semestre\", \"período\"),\n",
        "    (\"Onde os alunos do curso de Engenharia são matriculados\", \"estudante\"),\n",
        "    (\"Quantos professores tem em toda a universidade\", \"professor\"),\n",
        "    (\"Quantos professores lecionam no curso de Psicologia\", \"professor\"),\n",
        "    (\"Qual livro aborda o estudo de inteligência artificial\", \"livro\"),\n",
        "    (\"Quais são os livros recomendados para o curso de Direito\", \"livro\"),\n",
        "    (\"Quais as disciplinas do curso de Engenharia Civil\", \"disciplina\"),\n",
        "    (\"Qual o período de férias da universidade\", \"período\"),\n",
        "    (\"Quantos alunos estão matriculados no curso de ciencia da computacao\", \"estudante\"),\n",
        "    (\"Quais são os livros que falam sobre estatística\", \"livro\"),\n",
        "]\n",
        "\n",
        "class TopicTest:\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.vocab_size = len(dataset)\n",
        "        self.result = None\n",
        "        self.topics = []\n",
        "        self.test()\n",
        "\n",
        "    def test(self):\n",
        "        total_success = 0\n",
        "        total_errors = 0\n",
        "        errors = []\n",
        "        self.topics = list(set([topic for _, topic in self.dataset]))\n",
        "\n",
        "        for (input, output) in dataset:\n",
        "            classified_output = CLASSIFIER(input, self.topics)\n",
        "            classifier = classified_output['labels'][0]\n",
        "\n",
        "            if classifier == output:\n",
        "                total_success += 1\n",
        "            else:\n",
        "                errors.append({\"sentence\": input, \"output_expected\": output, \"output_model\": classifier, \"score\": classified_output['scores'][0]})\n",
        "                total_errors += 1\n",
        "\n",
        "        success_rate = total_success / self.vocab_size * 100\n",
        "        errors_rate = total_errors / self.vocab_size * 100\n",
        "\n",
        "        self.result = {\n",
        "            \"total_success\": total_success,\n",
        "            \"total_errors\": total_errors,\n",
        "            \"success_rate\": success_rate,\n",
        "            \"errors_rate\": errors_rate,\n",
        "            \"errors_ocurred\": errors\n",
        "        }\n",
        "\n",
        "    def explain_test(self):\n",
        "        print(f'Obteve {self.result[\"total_success\"]} acertos ({self.result[\"success_rate\"]:.2f}%) e {self.result[\"total_errors\"]} erro(s) ({self.result[\"errors_rate\"]:.2f}%) de {tester.vocab_size} amostras')\n",
        "\n",
        "tester = TopicTest(dataset=dataset)\n",
        "print(tester.result)\n",
        "tester.explain_test()\n",
        "\n",
        "input = response_llm\n",
        "classified_output = CLASSIFIER(input, [\"disciplina\", \"curso\", \"período\", \"estudante\", \"professor\", \"livro\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd9c23e",
      "metadata": {
        "id": "1dd9c23e"
      },
      "outputs": [],
      "source": [
        "from guardrails.hub import NSFWText\n",
        "from guardrails import Guard\n",
        "\n",
        "guard = Guard().use(NSFWText, threshold=0.8, validation_method=\"sentence\", on_fail=\"exception\")\n",
        "\n",
        "guard.validate(\n",
        "    \"Christopher Nolan's Tenet is a mind-bending action thriller that will keep you on the edge of your seat. The film is a must-watch for all Nolan fans.\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    guard.validate(\n",
        "        \"\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c309f19",
      "metadata": {
        "id": "3c309f19"
      },
      "outputs": [],
      "source": [
        "# Import Guard and Validator\n",
        "from guardrails import Guard\n",
        "from guardrails.hub import SimilarToDocument\n",
        "\n",
        "# Initialize The Guard with this validator\n",
        "guard = Guard().use(\n",
        "    SimilarToDocument,\n",
        "    document=\"\"\"\n",
        "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data.\n",
        "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities.\n",
        "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
        "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning.\n",
        "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
        "    \"\"\",\n",
        "    threshold=0.7,\n",
        "    model=\"all-MiniLM-L6-v2\",\n",
        "    on_fail=\"exception\",\n",
        ")\n",
        "\n",
        "# Test passing response\n",
        "guard.validate(\n",
        "    \"\"\"\n",
        "    Large Language Models (LLMs) are a type of neural network that can be trained on large amounts of text\n",
        "    data to generate human-like text. These models have been used in a variety of applications, including\n",
        "    machine translation, text summarization, and question answering.\n",
        "    \"\"\"\n",
        ")  # Pass\n",
        "\n",
        "try:\n",
        "    # Test failing response\n",
        "    guard.validate(\n",
        "        \"\"\"\n",
        "        Graph neural networks (GNNs) are specialized neural networks that can operate on graph data\n",
        "        structures. These networks are designed to capture the relationships between nodes in a graph\n",
        "        and can be used for a variety of tasks, including node classification, link prediction, and graph classification.\n",
        "        \"\"\"\n",
        "    )  # Fail\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690c6d24",
      "metadata": {
        "id": "690c6d24"
      },
      "outputs": [],
      "source": [
        "eureca_response = \"\"\"\n",
        "{\n",
        "    'sexo': {\n",
        "        'feminino': {\n",
        "            'quantidade': 194,\n",
        "            'estado_civil': {\n",
        "                'Casado': 2,\n",
        "                'Solteiro': 186,\n",
        "                'Divorciado': 1,\n",
        "                '-': 5\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 194,\n",
        "                'estrangeira': 0\n",
        "            },\n",
        "            'estados': {\n",
        "                'PE': 17,\n",
        "                'PB': 146,\n",
        "                'RJ': 4,\n",
        "                'RN': 4,\n",
        "                'CE': 3,\n",
        "                'SP': 7,\n",
        "                'MG': 1,\n",
        "                'MA': 2,\n",
        "                'AL': 1,\n",
        "                'PA': 1,\n",
        "                'BA': 1,\n",
        "                'PI': 2,\n",
        "                None: 5\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 18,\n",
        "                'idade_maxima': 39,\n",
        "                'media_idades': 22.47\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L1': 14,\n",
        "                'L6': 17,\n",
        "                '-': 59,\n",
        "                'L2': 26,\n",
        "                'L5': 13,\n",
        "                'L13': 1,\n",
        "                'L14': 1,\n",
        "                'Bon. estadual': 41,\n",
        "                'L9': 1,\n",
        "                'LB_PPI': 10,\n",
        "                'LI_PPI': 6,\n",
        "                'LB_EP': 2,\n",
        "                'LI_PCD': 3\n",
        "            },\n",
        "            'cor': {\n",
        "                'Branca': 98,\n",
        "                'Parda': 87,\n",
        "                'Preta': 4,\n",
        "                'Não declarada': 5\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 7.62},\n",
        "                'tipo_de_ensino_medio': {\n",
        "                    'Somente escola pública': 97,\n",
        "                    'Somente escola privada': 96,\n",
        "                    'Pública e privada, tendo ficado mais tempo em escola privada': 1\n",
        "                }\n",
        "            },\n",
        "\n",
        "        'masculino': {\n",
        "            'quantidade': 709,\n",
        "            'estado_civil': {\n",
        "                'Solteiro': 685,\n",
        "                'Casado': 6,\n",
        "                '-': 17,\n",
        "                'Divorciado': 1\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 708,\n",
        "                'estrangeira': 1\n",
        "            },\n",
        "            'estados': {\n",
        "                'PB': 528,\n",
        "                None: 21,\n",
        "                'SP': 24,\n",
        "                'PE': 49,\n",
        "                'RJ': 22,\n",
        "                'CE': 15,\n",
        "                'RN': 13,\n",
        "                'DF': 2,\n",
        "                'TO': 1,\n",
        "                'AL': 3,\n",
        "                'BA': 14,\n",
        "                'MA': 4,\n",
        "                'PR': 1,\n",
        "                'MS': 1,\n",
        "                'PA': 2,\n",
        "                'MG': 3,\n",
        "                'PI': 4,\n",
        "                'AP': 1,\n",
        "                'RO': 1\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 17,\n",
        "                'idade_maxima': 44,\n",
        "                'media_idades': 22.79\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L2': 78,\n",
        "                '-': 250,\n",
        "                'L1': 51,\n",
        "                'L6': 68,\n",
        "                'L5': 56,\n",
        "                'L10': 3,\n",
        "                'L13': 3,\n",
        "                'L9': 3,\n",
        "                'Bon. estadual': 129,\n",
        "                'L14': 1,\n",
        "                'LI_PPI': 22,\n",
        "                'LB_PPI': 22,\n",
        "                'LB_PCD': 5,\n",
        "                'LI_EP': 9,\n",
        "                'LB_EP': 7,\n",
        "                'LI_PCD': 2\n",
        "            },\n",
        "            'cor': {\n",
        "                'Parda': 291,\n",
        "                'Branca': 360,\n",
        "                'Preta': 33,\n",
        "                'Amarela': 7,\n",
        "                'Indígena': 1,\n",
        "                'Não declarada': 17\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 6.79\n",
        "            },\n",
        "            'tipo_de_ensino_medio': {\n",
        "                'Somente escola pública': 347,\n",
        "                'Somente escola privada': 359,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola pública': 1,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola privada': 2\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "llm_response = \"\"\"\n",
        "        ### Alunas (Feminino)\n",
        "\n",
        "        - **Quantidade Total**: 183\n",
        "        - **Estado Civil**\n",
        "        - Solteiro: 175\n",
        "        - Casado:3\n",
        "        - **Nacionalidade**: 100% Brasileira\n",
        "        - **Principais Estados**\n",
        "        -PB:139\n",
        "        - PE:17\n",
        "        - **Idade**:\n",
        "        - Média: 21.68 anos\n",
        "        - Mínima: 17 anos\n",
        "        - Máxima: 39 anos\n",
        "        - **Política Afirmativa**:\n",
        "        - Bon. estadual: 40\n",
        "        - L2: 26\n",
        "        - **Cor/Raça**:\n",
        "          -Branca: 92\n",
        "          -Parda: 83\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 6.78\n",
        "        - **Tipo de Ensino Médio**\n",
        "        - Somente escola pública: 93\n",
        "        - Somente escola privada:89\n",
        "\n",
        "        ### Alunos (Masculino)\n",
        "\n",
        "        ⁃ **Quantidade Total**: 658\n",
        "        - **Estado Civil**:\n",
        "        ⁃ Solteiro: 641\n",
        "        - Casado:6\n",
        "        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\n",
        "        - **Principais Estados**:\n",
        "        -PB:498\n",
        "        -PE: 47\n",
        "        ⁃ **Idade**:\n",
        "        ⁃ Média: 21.87 anos\n",
        "        - Minima: 17 anos\n",
        "        ⁃ Máxima: 43 anos\n",
        "        - **Política Afirmativa**\n",
        "        - Bon. estadual: 127\n",
        "        - L2:71\n",
        "        - **Cor/Raca**:\n",
        "        ⁃ Branca: 337\n",
        "        -Parda: 271\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 7.05\n",
        "        - **Tipo de Ensino Médio**:\n",
        "        ⁃ Somente escola pública: 329\n",
        "        - Somente escola privada: 327\n",
        "\n",
        "        Essas informações destacam a distribuição de gênero, origem\n",
        "        geográfica, política afirmativa, e outros aspectos demograficos e\n",
        "        educacionais dos alunos.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0738c310",
      "metadata": {
        "id": "0738c310"
      },
      "outputs": [],
      "source": [
        "from guardrails import Guard\n",
        "from guardrails.hub import SimilarToDocument\n",
        "\n",
        "guard = Guard().use(\n",
        "    SimilarToDocument,\n",
        "    document=eureca_response,\n",
        "    threshold=0.7,\n",
        "    model=\"all-MiniLM-L6-v2\",\n",
        "    on_fail=\"exception\",\n",
        ")\n",
        "\n",
        "guard.validate(llm_response)\n",
        "\n",
        "try:\n",
        "    guard.validate(\n",
        "        \"\"\"\n",
        "        Graph neural networks (GNNs) are specialized neural networks that can operate on graph data\n",
        "        structures. These networks are designed to capture the relationships between nodes in a graph\n",
        "        and can be used for a variety of tasks, including node classification, link prediction, and graph classification.\n",
        "        \"\"\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
