{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3bd818db-0d5f-4c22-9fe1-45707038e077",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bd818db-0d5f-4c22-9fe1-45707038e077",
        "outputId": "d269e842-c6bc-4478-9d1d-2763cd059820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/bin/python3.10: No module named pip\n",
            "/usr/bin/python3.10: No module named pip\n",
            "/bin/bash: line 1: guardrails: command not found\n",
            "/bin/bash: line 1: guardrails: command not found\n",
            "/usr/bin/python3.10: No module named spacy\n",
            "/bin/bash: line 1: guardrails: command not found\n",
            "/bin/bash: line 1: guardrails: command not found\n",
            "/bin/bash: line 1: guardrails: command not found\n"
          ]
        }
      ],
      "source": [
        "!python3.10 -m pip install guardrails-ai\n",
        "!python3.10 -m pip install urllib3\n",
        "!guardrails hub install hub://guardrails/detect_pii\n",
        "!guardrails hub install hub://guardrails/teste --quiet\n",
        "!python3.10 -m spacy download pt_core_news_sm\n",
        "!guardrails hub install hub://guardrails/pii --quiet\n",
        "!guardrails hub install hub://guardrails/nsfw_text\n",
        "!guardrails hub install hub://guardrails/similar_to_document --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "dd1c6e5a-b167-43c1-bd27-bc5eb0764bdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "dd1c6e5a-b167-43c1-bd27-bc5eb0764bdf",
        "outputId": "d414a866-003c-4655-fea1-76318af07d4f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'guardrails'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6d1609c8cc91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mguardrails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregister_validator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFailResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPassResult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mguardrails\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGuard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOnFailAction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mguardrails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDetectPII\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'guardrails'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from guardrails.validators import (register_validator, Validator, FailResult, ValidationResult, PassResult)\n",
        "from guardrails import Guard, OnFailAction\n",
        "from guardrails.hub import DetectPII\n",
        "from typing import Any, Dict, Optional, Callable, List\n",
        "\n",
        "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, RecognizerResult, Pattern\n",
        "import re\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "import unicodedata\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9319c2cc",
      "metadata": {
        "id": "9319c2cc"
      },
      "source": [
        "# Similaridade entre textos\n",
        "\n",
        "- Aqui encontra-se métodos de similaridade entre para verificar se o modelo está ou não alucinando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59bd18b",
      "metadata": {
        "id": "e59bd18b"
      },
      "outputs": [],
      "source": [
        "# Usando BERT para usar seus Embeddings\n",
        "\n",
        "if os.path.isdir(\"./bert_tokenizer\") and os.path.isdir(\"./bert_model\"):\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"./bert_tokenizer\")\n",
        "    model = BertModel.from_pretrained(\"./bert_model\")\n",
        "else:\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    tokenizer.save_pretrained(\"./bert_tokenizer\")\n",
        "    model.save_pretrained(\"./bert_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5cea0ee",
      "metadata": {
        "id": "b5cea0ee"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Descrição: Remove pontuação do texto\n",
        "\n",
        "    Args:\n",
        "        text: O texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Retorna o texto sem símbolos de pontuação\n",
        "\"\"\"\n",
        "def remove_pointing(text: str) -> str:\n",
        "    ans = \"\"\n",
        "    for c in text:\n",
        "          if unicodedata.category(c) != 'Po':\n",
        "               ans+=c\n",
        "    return ans\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição: Remove os acentos das palavras do texto\n",
        "\n",
        "    Args:\n",
        "        text: O texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Retorna o texto sem acentos\n",
        "\"\"\"\n",
        "def remove_accent(text: str) -> str:\n",
        "    nfkd = unicodedata.normalize('NFKD', text)\n",
        "    ans = \"\"\n",
        "    for c in nfkd:\n",
        "         if not unicodedata.combining(c):\n",
        "              ans += c\n",
        "    return ans\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição: Aplica lematização no texto\n",
        "\n",
        "    Args:\n",
        "        text: O texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Retorna o texto lematizado\n",
        "\"\"\"\n",
        "def lemmatize(text: str) -> str:\n",
        "    nlp = spacy.load('pt_core_news_sm')\n",
        "    doc = nlp(text)\n",
        "    return \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição: Remove as palavras irrelevantes do texto\n",
        "\n",
        "    Args:\n",
        "        words:  texto a ser tratado\n",
        "\n",
        "    Returns:\n",
        "        Lista de string sem as palavras irrelevantes\n",
        "\"\"\"\n",
        "def remove_stopwords(text: str) -> str:\n",
        "    text_without_pointing_and_accent = remove_accent(remove_pointing(text))\n",
        "    lemmatized_text = lemmatize(text_without_pointing_and_accent)\n",
        "    words_splitted = lemmatized_text.split()\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    relevant_text = \"\"\n",
        "    for word in words_splitted:\n",
        "        if word.lower() not in stop_words and len(word) > 2 and len(word) < 15:\n",
        "            relevant_text += re.sub(r'[^a-zA-Z0-9]', '', word.lower()) + \" \"\n",
        "\n",
        "    return relevant_text\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Retorna os embeddings do texto passado como parâmetro da função.\n",
        "\n",
        "    Args:\n",
        "        text: texto usado para criar os embeddings\n",
        "\n",
        "    returns:\n",
        "        Retorna os Embeddings.\n",
        "\"\"\"\n",
        "def generate_embeddings(text: str) -> List[List]:\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    embeddings = outputs.last_hidden_state\n",
        "    sentence_embedding = embeddings.mean(dim=1)\n",
        "\n",
        "    return sentence_embedding\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Calcula a similaridae cosseno entre dois trechos de textos.\n",
        "        Gera-se os embeddings para cada texto e em seguida, fazemos a similarida usando os embeddings.\n",
        "\n",
        "    args:\n",
        "        text1: texto usado para calcular a similaridade.\n",
        "        text1: texto usado para calcular a similaridade.\n",
        "\n",
        "    returns: Grau de similaridade em um intervalo fechado entre 0 (baixo) e 1 (alto).\n",
        "\"\"\"\n",
        "def cosine_similarity(text1: str, text2: str) -> float:\n",
        "    emb_text1 = generate_embeddings(text1)\n",
        "    emb_text2 = generate_embeddings(text2)\n",
        "\n",
        "    emb_text1 = emb_text1.cpu().numpy()\n",
        "    emb_text2 = emb_text2.cpu().numpy()\n",
        "\n",
        "    dot_product = np.dot(emb_text1, emb_text2.T)\n",
        "    text1Norm = np.linalg.norm(emb_text1)\n",
        "    text2Norm = np.linalg.norm(emb_text2)\n",
        "\n",
        "    return dot_product / (text1Norm * text2Norm)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Divide o texto em alguns pedaços de frases.\n",
        "\n",
        "    Args:\n",
        "        text: texto a ser dividido.\n",
        "        max_length: tamanho máximo de cada divisão.\n",
        "\n",
        "    returns: Lista de frases.\n",
        "\"\"\"\n",
        "def split_text(text, max_length: int = 10) -> List:\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    chunks = [tokenizer.convert_tokens_to_string(tokens[i:i + max_length]) for i in range(0, len(tokens), max_length)]\n",
        "\n",
        "    return chunks\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Calcula a similaridade entre dois textos.\n",
        "\n",
        "    Args:\n",
        "        text1: texto usado para calcular a similaridade.\n",
        "        text2: texto usado para calcular a similaridade.\n",
        "\n",
        "    returns:\n",
        "        Similaridade cosseno.\n",
        "\n",
        "\"\"\"\n",
        "def similarity_between_texts(text1, text2) -> float:\n",
        "\n",
        "    text1 = remove_stopwords(text1)\n",
        "    text2 = remove_stopwords(text2)\n",
        "\n",
        "    print(text1)\n",
        "    print(text2)\n",
        "\n",
        "    split_text1 = split_text(text1)\n",
        "    split_text2 = split_text(text2)\n",
        "\n",
        "    similarities = []\n",
        "\n",
        "    if len(split_text1) == 0 or len(split_text2) == 0:\n",
        "        return 0\n",
        "\n",
        "    for text1 in split_text1:\n",
        "        for text2 in split_text2:\n",
        "            similarities.append(cosine_similarity(text1, text2)[0][0])\n",
        "\n",
        "    media = np.mean(similarities)\n",
        "    print(media, similarities)\n",
        "    return media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee83a34",
      "metadata": {
        "id": "dee83a34"
      },
      "outputs": [],
      "source": [
        "# Testes\n",
        "\n",
        "response_eureca = \"\"\"\n",
        "{\n",
        "    'sexo': {\n",
        "        'feminino': {\n",
        "            'quantidade': 194,\n",
        "            'estado_civil': {\n",
        "                'Casado': 2,\n",
        "                'Solteiro': 186,\n",
        "                'Divorciado': 1,\n",
        "                '-': 5\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 194,\n",
        "                'estrangeira': 0\n",
        "            },\n",
        "            'estados': {\n",
        "                'PE': 17,\n",
        "                'PB': 146,\n",
        "                'RJ': 4,\n",
        "                'RN': 4,\n",
        "                'CE': 3,\n",
        "                'SP': 7,\n",
        "                'MG': 1,\n",
        "                'MA': 2,\n",
        "                'AL': 1,\n",
        "                'PA': 1,\n",
        "                'BA': 1,\n",
        "                'PI': 2,\n",
        "                None: 5\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 18,\n",
        "                'idade_maxima': 39,\n",
        "                'media_idades': 22.47\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L1': 14,\n",
        "                'L6': 17,\n",
        "                '-': 59,\n",
        "                'L2': 26,\n",
        "                'L5': 13,\n",
        "                'L13': 1,\n",
        "                'L14': 1,\n",
        "                'Bon. estadual': 41,\n",
        "                'L9': 1,\n",
        "                'LB_PPI': 10,\n",
        "                'LI_PPI': 6,\n",
        "                'LB_EP': 2,\n",
        "                'LI_PCD': 3\n",
        "            },\n",
        "            'cor': {\n",
        "                'Branca': 98,\n",
        "                'Parda': 87,\n",
        "                'Preta': 4,\n",
        "                'Não declarada': 5\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 7.62},\n",
        "                'tipo_de_ensino_medio': {\n",
        "                    'Somente escola pública': 97,\n",
        "                    'Somente escola privada': 96,\n",
        "                    'Pública e privada, tendo ficado mais tempo em escola privada': 1\n",
        "                }\n",
        "            },\n",
        "\n",
        "        'masculino': {\n",
        "            'quantidade': 709,\n",
        "            'estado_civil': {\n",
        "                'Solteiro': 685,\n",
        "                'Casado': 6,\n",
        "                '-': 17,\n",
        "                'Divorciado': 1\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 708,\n",
        "                'estrangeira': 1\n",
        "            },\n",
        "            'estados': {\n",
        "                'PB': 528,\n",
        "                None: 21,\n",
        "                'SP': 24,\n",
        "                'PE': 49,\n",
        "                'RJ': 22,\n",
        "                'CE': 15,\n",
        "                'RN': 13,\n",
        "                'DF': 2,\n",
        "                'TO': 1,\n",
        "                'AL': 3,\n",
        "                'BA': 14,\n",
        "                'MA': 4,\n",
        "                'PR': 1,\n",
        "                'MS': 1,\n",
        "                'PA': 2,\n",
        "                'MG': 3,\n",
        "                'PI': 4,\n",
        "                'AP': 1,\n",
        "                'RO': 1\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 17,\n",
        "                'idade_maxima': 44,\n",
        "                'media_idades': 22.79\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L2': 78,\n",
        "                '-': 250,\n",
        "                'L1': 51,\n",
        "                'L6': 68,\n",
        "                'L5': 56,\n",
        "                'L10': 3,\n",
        "                'L13': 3,\n",
        "                'L9': 3,\n",
        "                'Bon. estadual': 129,\n",
        "                'L14': 1,\n",
        "                'LI_PPI': 22,\n",
        "                'LB_PPI': 22,\n",
        "                'LB_PCD': 5,\n",
        "                'LI_EP': 9,\n",
        "                'LB_EP': 7,\n",
        "                'LI_PCD': 2\n",
        "            },\n",
        "            'cor': {\n",
        "                'Parda': 291,\n",
        "                'Branca': 360,\n",
        "                'Preta': 33,\n",
        "                'Amarela': 7,\n",
        "                'Indígena': 1,\n",
        "                'Não declarada': 17\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 6.79\n",
        "            },\n",
        "            'tipo_de_ensino_medio': {\n",
        "                'Somente escola pública': 347,\n",
        "                'Somente escola privada': 359,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola pública': 1,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola privada': 2\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "response_llm = \"\"\"\n",
        "        ### Alunas (Feminino)\n",
        "\n",
        "        - **Quantidade Total**: 183\n",
        "        - **Estado Civil**\n",
        "        - Solteiro: 175\n",
        "        - Casado:3\n",
        "        - **Nacionalidade**: 100% Brasileira\n",
        "        - **Principais Estados**\n",
        "        -PB:139\n",
        "        - PE:17\n",
        "        - **Idade**:\n",
        "        - Média: 21.68 anos\n",
        "        - Mínima: 17 anos\n",
        "        - Máxima: 39 anos\n",
        "        - **Política Afirmativa**:\n",
        "        - Bon. estadual: 40\n",
        "        - L2: 26\n",
        "        - **Cor/Raça**:\n",
        "          -Branca: 92\n",
        "          -Parda: 83\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 6.78\n",
        "        - **Tipo de Ensino Médio**\n",
        "        - Somente escola pública: 93\n",
        "        - Somente escola privada:89\n",
        "\n",
        "        ### Alunos (Masculino)\n",
        "\n",
        "        ⁃ **Quantidade Total**: 658\n",
        "        - **Estado Civil**:\n",
        "        ⁃ Solteiro: 641\n",
        "        - Casado:6\n",
        "        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\n",
        "        - **Principais Estados**:\n",
        "        -PB:498\n",
        "        -PE: 47\n",
        "        ⁃ **Idade**:\n",
        "        ⁃ Média: 21.87 anos\n",
        "        - Minima: 17 anos\n",
        "        ⁃ Máxima: 43 anos\n",
        "        - **Política Afirmativa**\n",
        "        - Bon. estadual: 127\n",
        "        - L2:71\n",
        "        - **Cor/Raca**:\n",
        "        ⁃ Branca: 337\n",
        "        -Parda: 271\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 7.05\n",
        "        - **Tipo de Ensino Médio**:\n",
        "        ⁃ Somente escola pública: 329\n",
        "        - Somente escola privada: 327\n",
        "\n",
        "        Essas informações destacam a distribuição de gênero, origem\n",
        "        geográfica, política afirmativa, e outros aspectos demograficos e\n",
        "        educacionais dos alunos.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "946741fc",
      "metadata": {
        "id": "946741fc"
      },
      "source": [
        "# Guardrails\n",
        "\n",
        "- Guardrails é uma estrutura Python que ajuda a construir aplicativos de IA confiáveis, executando duas funções principais:\n",
        "\n",
        "- Guardrails executa protetores de entrada/saída em sua aplicação que detectam, quantificam e mitigam a presença de tipos específicos de riscos. Para ver o conjunto completo de riscos, confira Guardrails Hub.\n",
        "- Guardrails ajudam você a gerar dados estruturados de LLMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d60d85db",
      "metadata": {
        "id": "d60d85db"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Descrição:\n",
        "        Calcula a similaridade entre dois textos e valida se a similaridade está acima de um limiar definido pelo usuário.\n",
        "\n",
        "    Returns:\n",
        "        Retorna a similaridade entre dois textos.\n",
        "\"\"\"\n",
        "@register_validator(name=\"guardrails/teste\", data_type=\"string\")\n",
        "class ValidadorDeSimilaridade(Validator):\n",
        "    def __init__(self, texto1: str, texto2: str, match_type: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
        "        super().__init__(on_fail=on_fail, match_type=match_type)\n",
        "\n",
        "        self.texto1 = texto1\n",
        "        self.texto2 = texto2\n",
        "\n",
        "    def validate(self, value: Any, metadata: Dict = {}) -> ValidationResult:\n",
        "        similarity = float(f\"{similarity_between_texts(self.texto1, self.texto2):.1f}\")\n",
        "        print(similarity)\n",
        "\n",
        "        ideal_similarity = 0.7\n",
        "        if similarity < ideal_similarity:\n",
        "            print(f\"{value}: Similaridade baixa {similarity} (menor que {ideal_similarity})\")\n",
        "            return FailResult(error_message=\"Erro\")\n",
        "\n",
        "        print(f\"{value}: Similaridade alta de {similarity} (igual ou acima de {ideal_similarity})\")\n",
        "        return PassResult()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d02db314",
      "metadata": {
        "id": "d02db314"
      },
      "outputs": [],
      "source": [
        "def teste(texto1, texto2):\n",
        "    guard = Guard().use(\n",
        "        ValidadorDeSimilaridade(texto1=texto1, texto2=texto2)\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        guard.parse(\"Agente Inteligente\").model_validate\n",
        "        print(\"Passou no teste de similaridade cosseno!\")\n",
        "    except Exception as e:\n",
        "        print(\"Ocorreu um erro: \", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfeb964",
      "metadata": {
        "id": "dbfeb964"
      },
      "outputs": [],
      "source": [
        "texto1 = \"\"\"\n",
        "lula\n",
        "\"\"\"\n",
        "\n",
        "texto2 = \"\"\"\n",
        "carro\n",
        "\"\"\"\n",
        "\n",
        "teste(texto1=texto1, texto2=texto2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed11eb54",
      "metadata": {
        "id": "ed11eb54"
      },
      "outputs": [],
      "source": [
        "texto1 = \"\"\"\n",
        "de onde sao os alunos de ciencia da computacao? liste todos os estados\n",
        "\"\"\"\n",
        "\n",
        "texto2 = \"\"\"\n",
        "Os alunos de Ciência da Computação vêm de diversos estados,\n",
        "incluindo:\n",
        "\n",
        "\n",
        "Pernambuco (PE)\n",
        "Rio de Janeiro (RJ)\n",
        "São Paulo (SP)\n",
        "Minas Gerais (MG)\n",
        "Bahia (BA)\n",
        "\n",
        "\n",
        "Esses sao alguns exemplos dos estados de origem dos alunos.\"\"\"\n",
        "\n",
        "teste(texto1=texto1, texto2=texto2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8c60d1",
      "metadata": {
        "id": "8b8c60d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a4f50c8",
      "metadata": {
        "id": "2a4f50c8"
      },
      "outputs": [],
      "source": [
        "texto1 = \"Lula é o presidente do Brasil\"\n",
        "texto2 = \"Lula não é o presidente do Brasil\"\n",
        "\n",
        "teste(texto1=texto1, texto2=texto2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ba3384",
      "metadata": {
        "id": "07ba3384"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Descrição:\n",
        "        A partir de um texto passado através do método parse, este guardrail camufla a matricula do usuário no texto e retorna o texto camuflado.\n",
        "\"\"\"\n",
        "@register_validator(name=\"guardrails/enrollment\", data_type=\"string\")\n",
        "class PIIValidator(Validator):\n",
        "    def __init__(self, on_match: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
        "        super().__init__(on_match=on_match, on_fail=on_fail)\n",
        "\n",
        "    def validate(self, value: str, metadata: Dict = {}) -> ValidationResult:\n",
        "        year = str(dt.datetime.now().year)[2:]\n",
        "\n",
        "        enrollment = r\"\\b\\d{1}[1-\" + year[0] + r\"]\" + r\"[0-\" + year[1] + r\"]\" + r\"[12]\\d{5}\\b\"\n",
        "        enrollment_pattern = Pattern(name=\"Enrollment_Pattern\", regex=enrollment, score=0.6)\n",
        "\n",
        "        enrollment_recognizer = PatternRecognizer(name=\"MATRICULA\", patterns=[enrollment_pattern], supported_entity=\"Enrollment_Pattern\", supported_language=\"en\")\n",
        "\n",
        "        analyzer = AnalyzerEngine()\n",
        "        analyzer.registry.add_recognizer(enrollment_recognizer)\n",
        "\n",
        "        results = analyzer.analyze(text=value, entities=[\"Enrollment_Pattern\"], language=\"en\")\n",
        "\n",
        "        if results:\n",
        "            for result in results:\n",
        "                start, end = result.start, result.end\n",
        "                value = value[:start] + \"<MATRICULA>\" + value[end:]\n",
        "            return FailResult(error_message=value)\n",
        "\n",
        "        return PassResult()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "185b98f9",
      "metadata": {
        "id": "185b98f9"
      },
      "outputs": [],
      "source": [
        "guardas_eureca = Guard().use(PIIValidator)\n",
        "\n",
        "try:\n",
        "    guardas_eureca.parse(\"A minha matricula é o seguinte: 221199999, busque informaões sobre ela\").model_validate\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3185903b",
      "metadata": {
        "id": "3185903b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\"\"\"\n",
        "Descrição:\n",
        "    Guardrail para dado um texto, camuflar o seu CPF.\n",
        "\"\"\"\n",
        "@register_validator(name=\"guardrails/cpf\", data_type=\"string\")\n",
        "class PIIValidatorCPF(Validator):\n",
        "    def __init__(self, on_match: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
        "        super().__init__(on_match=on_match, on_fail=on_fail)\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Descrição:\n",
        "        Verifica se a possivel sequência de números é ou não um CPF através do calculo dos digitos verificadores dos 9 primeiros números.\n",
        "\n",
        "    Args:\n",
        "        cpf_user: CPF a ser validado.\n",
        "\n",
        "    returns:\n",
        "        Retorna um valor booleano.\n",
        "        True se a sequência de números é um CPF e False, caso contrário.\n",
        "    \"\"\"\n",
        "    def validate_digit_verificator(self, cpf_user):\n",
        "        if len(set(cpf_user)) == 1: return False\n",
        "\n",
        "        cpf = cpf_user[:9]\n",
        "        sum = 0\n",
        "        for i in range(1, len(cpf) + 1):\n",
        "            sum += i * int(cpf[i - 1])\n",
        "        first_digit_verificator = sum % 11\n",
        "\n",
        "        if first_digit_verificator == 10:\n",
        "            first_digit_verificator = 0\n",
        "\n",
        "\n",
        "        sum = 0\n",
        "        cpf = cpf + str(first_digit_verificator)\n",
        "        for i in range(len(cpf)):\n",
        "            sum += i * int(cpf[i])\n",
        "        second_digit_verificator = sum % 11\n",
        "\n",
        "        if second_digit_verificator == 10:\n",
        "            second_digit_verificator = 0\n",
        "\n",
        "        cpf = cpf[:9] + str(first_digit_verificator) + str(second_digit_verificator)\n",
        "        return cpf == cpf_user\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Descrição:\n",
        "        Camufla o CPF de um texto, buscando as posições onde os possiveis CPFs ocorrem.\n",
        "\n",
        "    Args:\n",
        "        text: string do cpf a ser validado.\n",
        "\n",
        "    returns:\n",
        "        Retorna um texto com o CPF camuflado.\n",
        "    \"\"\"\n",
        "    def replace_valid_cpfs(self, text) -> str:\n",
        "        cpf_pattern =r\"\\b\\d{3}[^a-zA-Z]*\\d{3}[^a-zA-Z]*\\d{3}[^a-zA-Z]*\\d{2}\\b\"\n",
        "\n",
        "        def validate_and_replace(match):\n",
        "            cpf = match.group(0)\n",
        "            cpf_numbers = re.sub(r\"[^\\d]\", \"\", cpf)\n",
        "\n",
        "            if self.validate_digit_verificator(cpf_numbers):\n",
        "                return \"<CPF>\"\n",
        "            return cpf\n",
        "\n",
        "        return re.sub(cpf_pattern, validate_and_replace, text)\n",
        "\n",
        "    def validate(self, value: str, metadata: Dict = {}) -> ValidationResult:\n",
        "        result = self.replace_valid_cpfs(value)\n",
        "\n",
        "        if \"<CPF>\" in result:\n",
        "            return FailResult(error_message=result)\n",
        "        return PassResult()\n",
        "\n",
        "\n",
        "guardas_eureca = Guard().use(PIIValidatorCPF)\n",
        "\n",
        "try:\n",
        "    result = guardas_eureca.parse(\"O meu CPF é o seguinte: 99999999999, busque informaões sobre ele\").model_validate\n",
        "except Exception as e:\n",
        "    print(str(e)[41:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cadd8f4c",
      "metadata": {
        "id": "cadd8f4c"
      },
      "outputs": [],
      "source": [
        "guarda_email = Guard().use(DetectPII(pii_entities=\"pii\", on_fail=\"fix\"))\n",
        "\n",
        "text = \"\"\"\n",
        "Meus emails são demo@lol.com ou dominio@gmail.com ou dominio@hotmail.com e dominio@hotmail.com.br;\n",
        "e os meus números de telefones são esses (99) 999999999 ou (99)999999999 ou 99999999999 e 99999999999,\n",
        "busque no google.com.br ou uol.com.\n",
        "\"\"\"\n",
        "output = guarda_email.parse(\n",
        "    llm_output=text,\n",
        "    metadata={\"pii_entities\": [\"EMAIL_ADDRESS\", \"URL\", \"PHONE_NUMBER\"]},\n",
        ")\n",
        "\n",
        "print(output.validated_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e9ecaa",
      "metadata": {
        "id": "08e9ecaa"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "\n",
        "\"\"\"\n",
        "    Descrição:\n",
        "        Valida se a LLM alucinou baseado na saída da LLM e os dados do Eureca.\n",
        "\"\"\"\n",
        "@register_validator(name=\"hallucination_detector\", data_type=\"string\")\n",
        "class HallucinationValidation(Validator):\n",
        "    def __init__(\n",
        "            self,\n",
        "            embedding_model: Optional[str] = None,\n",
        "            entailment_model: Optional[str] = None,\n",
        "            sources: Optional[List[str]] = None,\n",
        "            **kwargs\n",
        "        ):\n",
        "        if embedding_model is None:\n",
        "            embedding_model = 'all-MiniLM-L6-v2'\n",
        "        self.embedding_model = SentenceTransformer(embedding_model)\n",
        "\n",
        "        self.sources = sources\n",
        "\n",
        "        if entailment_model is None:\n",
        "            entailment_model = 'GuardrailsAI/finetuned_nli_provenance'\n",
        "        self.nli_pipeline = pipeline(\"text-classification\", model=entailment_model)\n",
        "\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def validate(\n",
        "        self, value: str, metadata: Optional[Dict[str, str]] = None\n",
        "    ) -> ValidationResult:\n",
        "        sentences = self.split_sentences(value)\n",
        "\n",
        "        relevant_sources = self.find_relevant_sources(sentences, self.sources)\n",
        "\n",
        "        entailed_sentences = []\n",
        "        hallucinated_sentences = []\n",
        "        for sentence in sentences:\n",
        "            is_entailed = self.check_entailment(sentence, relevant_sources)\n",
        "            if not is_entailed:\n",
        "                hallucinated_sentences.append(sentence)\n",
        "            else:\n",
        "                entailed_sentences.append(sentence)\n",
        "\n",
        "        if len(hallucinated_sentences) > 0:\n",
        "            return FailResult(\n",
        "                error_message=f\"Alucinação detectada: {hallucinated_sentences}\",\n",
        "            )\n",
        "\n",
        "        return PassResult()\n",
        "\n",
        "    def split_sentences(self, text: str) -> List[str]:\n",
        "        return nltk.sent_tokenize(text)\n",
        "\n",
        "    def find_relevant_sources(self, sentences: str, sources: List[str]) -> List[str]:\n",
        "        source_embeds = self.embedding_model.encode(sources)\n",
        "        sentence_embeds = self.embedding_model.encode(sentences)\n",
        "\n",
        "        relevant_sources = []\n",
        "\n",
        "        for sentence_idx in range(len(sentences)):\n",
        "            sentence_embed = sentence_embeds[sentence_idx, :].reshape(1, -1)\n",
        "            cos_similarities = np.sum(np.multiply(source_embeds, sentence_embed), axis=1)\n",
        "            top_sources = np.argsort(cos_similarities)[::-1][:5]\n",
        "            top_sources = [i for i in top_sources if cos_similarities[i] > 0.8]\n",
        "\n",
        "            relevant_sources.extend([sources[i] for i in top_sources])\n",
        "\n",
        "        return relevant_sources\n",
        "\n",
        "    def check_entailment(self, sentence: str, sources: List[str]) -> bool:\n",
        "        for source in sources:\n",
        "            output = self.nli_pipeline({'text': source, 'text_pair': sentence})\n",
        "            if output['label'] == 'entailment':\n",
        "                return True\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6041145",
      "metadata": {
        "id": "e6041145"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "model_name = \"GuardrailsAI/finetuned_nli_provenance\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "save_directory = \"./saved_models/finetuned_nli_provenance\"\n",
        "\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "model.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Modelo salvo em: {save_directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c230b65",
      "metadata": {
        "id": "1c230b65"
      },
      "outputs": [],
      "source": [
        "save_directory = \"./saved_models/finetuned_nli_provenance\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
        "model = AutoModel.from_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef2b3d2a",
      "metadata": {
        "id": "ef2b3d2a"
      },
      "outputs": [],
      "source": [
        "guard = Guard().use(\n",
        "    HallucinationValidation(\n",
        "        embedding_model='all-MiniLM-L6-v2',\n",
        "        entailment_model='./saved_models/finetuned_nli_provenance',\n",
        "        sources=[response_eureca],\n",
        "        on_fail=OnFailAction.EXCEPTION\n",
        "    )\n",
        ")\n",
        "\n",
        "guard.validate(response_llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8520a0d",
      "metadata": {
        "id": "f8520a0d"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "CLASSIFIER = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model='facebook/bart-large-mnli',\n",
        "    hypothesis_template=\"Verifique em qual tópico o texto acima melhor se adequa: {}.\",\n",
        "    multi_label=True,\n",
        ")\n",
        "\n",
        "dataset = [\n",
        "    (\"Quais são as disciplinas oferecidas no curso de Matemática\", \"disciplina\"),\n",
        "    (\"Quantos cursos a universidade oferece\", \"curso\"),\n",
        "    (\"Qual o calendário acadêmico deste semestre\", \"período\"),\n",
        "    (\"Onde os alunos do curso de Engenharia são matriculados\", \"estudante\"),\n",
        "    (\"Quantos professores tem em toda a universidade\", \"professor\"),\n",
        "    (\"Quantos professores lecionam no curso de Psicologia\", \"professor\"),\n",
        "    (\"Qual livro aborda o estudo de inteligência artificial\", \"livro\"),\n",
        "    (\"Quais são os livros recomendados para o curso de Direito\", \"livro\"),\n",
        "    (\"Quais as disciplinas do curso de Engenharia Civil\", \"disciplina\"),\n",
        "    (\"Qual o período de férias da universidade\", \"período\"),\n",
        "    (\"Quantos alunos estão matriculados no curso de ciencia da computacao\", \"estudante\"),\n",
        "    (\"Quais são os livros que falam sobre estatística\", \"livro\"),\n",
        "]\n",
        "\n",
        "class TopicTest:\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.vocab_size = len(dataset)\n",
        "        self.result = None\n",
        "        self.topics = []\n",
        "        self.test()\n",
        "\n",
        "    def test(self):\n",
        "        total_success = 0\n",
        "        total_errors = 0\n",
        "        errors = []\n",
        "        self.topics = list(set([topic for _, topic in self.dataset]))\n",
        "\n",
        "        for (input, output) in dataset:\n",
        "            classified_output = CLASSIFIER(input, self.topics)\n",
        "            classifier = classified_output['labels'][0]\n",
        "\n",
        "            if classifier == output:\n",
        "                total_success += 1\n",
        "            else:\n",
        "                errors.append({\"sentence\": input, \"output_expected\": output, \"output_model\": classifier, \"score\": classified_output['scores'][0]})\n",
        "                total_errors += 1\n",
        "\n",
        "        success_rate = total_success / self.vocab_size * 100\n",
        "        errors_rate = total_errors / self.vocab_size * 100\n",
        "\n",
        "        self.result = {\n",
        "            \"total_success\": total_success,\n",
        "            \"total_errors\": total_errors,\n",
        "            \"success_rate\": success_rate,\n",
        "            \"errors_rate\": errors_rate,\n",
        "            \"errors_ocurred\": errors\n",
        "        }\n",
        "\n",
        "    def explain_test(self):\n",
        "        print(f'Obteve {self.result[\"total_success\"]} acertos ({self.result[\"success_rate\"]:.2f}%) e {self.result[\"total_errors\"]} erro(s) ({self.result[\"errors_rate\"]:.2f}%) de {tester.vocab_size} amostras')\n",
        "\n",
        "tester = TopicTest(dataset=dataset)\n",
        "print(tester.result)\n",
        "tester.explain_test()\n",
        "\n",
        "input = response_llm\n",
        "classified_output = CLASSIFIER(input, [\"disciplina\", \"curso\", \"período\", \"estudante\", \"professor\", \"livro\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dd9c23e",
      "metadata": {
        "id": "1dd9c23e"
      },
      "outputs": [],
      "source": [
        "from guardrails.hub import NSFWText\n",
        "from guardrails import Guard\n",
        "\n",
        "guard = Guard().use(NSFWText, threshold=0.8, validation_method=\"sentence\", on_fail=\"exception\")\n",
        "\n",
        "guard.validate(\n",
        "    \"Christopher Nolan's Tenet is a mind-bending action thriller that will keep you on the edge of your seat. The film is a must-watch for all Nolan fans.\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    guard.validate(\n",
        "        \"\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c309f19",
      "metadata": {
        "id": "3c309f19"
      },
      "outputs": [],
      "source": [
        "# Import Guard and Validator\n",
        "from guardrails import Guard\n",
        "from guardrails.hub import SimilarToDocument\n",
        "\n",
        "# Initialize The Guard with this validator\n",
        "guard = Guard().use(\n",
        "    SimilarToDocument,\n",
        "    document=\"\"\"\n",
        "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data.\n",
        "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities.\n",
        "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
        "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning.\n",
        "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
        "    \"\"\",\n",
        "    threshold=0.7,\n",
        "    model=\"all-MiniLM-L6-v2\",\n",
        "    on_fail=\"exception\",\n",
        ")\n",
        "\n",
        "# Test passing response\n",
        "guard.validate(\n",
        "    \"\"\"\n",
        "    Large Language Models (LLMs) are a type of neural network that can be trained on large amounts of text\n",
        "    data to generate human-like text. These models have been used in a variety of applications, including\n",
        "    machine translation, text summarization, and question answering.\n",
        "    \"\"\"\n",
        ")  # Pass\n",
        "\n",
        "try:\n",
        "    # Test failing response\n",
        "    guard.validate(\n",
        "        \"\"\"\n",
        "        Graph neural networks (GNNs) are specialized neural networks that can operate on graph data\n",
        "        structures. These networks are designed to capture the relationships between nodes in a graph\n",
        "        and can be used for a variety of tasks, including node classification, link prediction, and graph classification.\n",
        "        \"\"\"\n",
        "    )  # Fail\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690c6d24",
      "metadata": {
        "id": "690c6d24"
      },
      "outputs": [],
      "source": [
        "eureca_response = \"\"\"\n",
        "{\n",
        "    'sexo': {\n",
        "        'feminino': {\n",
        "            'quantidade': 194,\n",
        "            'estado_civil': {\n",
        "                'Casado': 2,\n",
        "                'Solteiro': 186,\n",
        "                'Divorciado': 1,\n",
        "                '-': 5\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 194,\n",
        "                'estrangeira': 0\n",
        "            },\n",
        "            'estados': {\n",
        "                'PE': 17,\n",
        "                'PB': 146,\n",
        "                'RJ': 4,\n",
        "                'RN': 4,\n",
        "                'CE': 3,\n",
        "                'SP': 7,\n",
        "                'MG': 1,\n",
        "                'MA': 2,\n",
        "                'AL': 1,\n",
        "                'PA': 1,\n",
        "                'BA': 1,\n",
        "                'PI': 2,\n",
        "                None: 5\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 18,\n",
        "                'idade_maxima': 39,\n",
        "                'media_idades': 22.47\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L1': 14,\n",
        "                'L6': 17,\n",
        "                '-': 59,\n",
        "                'L2': 26,\n",
        "                'L5': 13,\n",
        "                'L13': 1,\n",
        "                'L14': 1,\n",
        "                'Bon. estadual': 41,\n",
        "                'L9': 1,\n",
        "                'LB_PPI': 10,\n",
        "                'LI_PPI': 6,\n",
        "                'LB_EP': 2,\n",
        "                'LI_PCD': 3\n",
        "            },\n",
        "            'cor': {\n",
        "                'Branca': 98,\n",
        "                'Parda': 87,\n",
        "                'Preta': 4,\n",
        "                'Não declarada': 5\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 7.62},\n",
        "                'tipo_de_ensino_medio': {\n",
        "                    'Somente escola pública': 97,\n",
        "                    'Somente escola privada': 96,\n",
        "                    'Pública e privada, tendo ficado mais tempo em escola privada': 1\n",
        "                }\n",
        "            },\n",
        "\n",
        "        'masculino': {\n",
        "            'quantidade': 709,\n",
        "            'estado_civil': {\n",
        "                'Solteiro': 685,\n",
        "                'Casado': 6,\n",
        "                '-': 17,\n",
        "                'Divorciado': 1\n",
        "            },\n",
        "            'nacionalidades': {\n",
        "                'brasileira': 708,\n",
        "                'estrangeira': 1\n",
        "            },\n",
        "            'estados': {\n",
        "                'PB': 528,\n",
        "                None: 21,\n",
        "                'SP': 24,\n",
        "                'PE': 49,\n",
        "                'RJ': 22,\n",
        "                'CE': 15,\n",
        "                'RN': 13,\n",
        "                'DF': 2,\n",
        "                'TO': 1,\n",
        "                'AL': 3,\n",
        "                'BA': 14,\n",
        "                'MA': 4,\n",
        "                'PR': 1,\n",
        "                'MS': 1,\n",
        "                'PA': 2,\n",
        "                'MG': 3,\n",
        "                'PI': 4,\n",
        "                'AP': 1,\n",
        "                'RO': 1\n",
        "            },\n",
        "            'idade': {\n",
        "                'idade_minima': 17,\n",
        "                'idade_maxima': 44,\n",
        "                'media_idades': 22.79\n",
        "            },\n",
        "            'politica_afirmativa': {\n",
        "                'L2': 78,\n",
        "                '-': 250,\n",
        "                'L1': 51,\n",
        "                'L6': 68,\n",
        "                'L5': 56,\n",
        "                'L10': 3,\n",
        "                'L13': 3,\n",
        "                'L9': 3,\n",
        "                'Bon. estadual': 129,\n",
        "                'L14': 1,\n",
        "                'LI_PPI': 22,\n",
        "                'LB_PPI': 22,\n",
        "                'LB_PCD': 5,\n",
        "                'LI_EP': 9,\n",
        "                'LB_EP': 7,\n",
        "                'LI_PCD': 2\n",
        "            },\n",
        "            'cor': {\n",
        "                'Parda': 291,\n",
        "                'Branca': 360,\n",
        "                'Preta': 33,\n",
        "                'Amarela': 7,\n",
        "                'Indígena': 1,\n",
        "                'Não declarada': 17\n",
        "            },\n",
        "            'renda_per_capita_ate': {\n",
        "                'renda_minima': 0.5,\n",
        "                'renda_maxima': 99.0,\n",
        "                'renda_media': 6.79\n",
        "            },\n",
        "            'tipo_de_ensino_medio': {\n",
        "                'Somente escola pública': 347,\n",
        "                'Somente escola privada': 359,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola pública': 1,\n",
        "                'Pública e privada, tendo ficado mais tempo em escola privada': 2\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "llm_response = \"\"\"\n",
        "        ### Alunas (Feminino)\n",
        "\n",
        "        - **Quantidade Total**: 183\n",
        "        - **Estado Civil**\n",
        "        - Solteiro: 175\n",
        "        - Casado:3\n",
        "        - **Nacionalidade**: 100% Brasileira\n",
        "        - **Principais Estados**\n",
        "        -PB:139\n",
        "        - PE:17\n",
        "        - **Idade**:\n",
        "        - Média: 21.68 anos\n",
        "        - Mínima: 17 anos\n",
        "        - Máxima: 39 anos\n",
        "        - **Política Afirmativa**:\n",
        "        - Bon. estadual: 40\n",
        "        - L2: 26\n",
        "        - **Cor/Raça**:\n",
        "          -Branca: 92\n",
        "          -Parda: 83\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 6.78\n",
        "        - **Tipo de Ensino Médio**\n",
        "        - Somente escola pública: 93\n",
        "        - Somente escola privada:89\n",
        "\n",
        "        ### Alunos (Masculino)\n",
        "\n",
        "        ⁃ **Quantidade Total**: 658\n",
        "        - **Estado Civil**:\n",
        "        ⁃ Solteiro: 641\n",
        "        - Casado:6\n",
        "        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\n",
        "        - **Principais Estados**:\n",
        "        -PB:498\n",
        "        -PE: 47\n",
        "        ⁃ **Idade**:\n",
        "        ⁃ Média: 21.87 anos\n",
        "        - Minima: 17 anos\n",
        "        ⁃ Máxima: 43 anos\n",
        "        - **Política Afirmativa**\n",
        "        - Bon. estadual: 127\n",
        "        - L2:71\n",
        "        - **Cor/Raca**:\n",
        "        ⁃ Branca: 337\n",
        "        -Parda: 271\n",
        "        - **Renda Per Capita**:\n",
        "        - Média: 7.05\n",
        "        - **Tipo de Ensino Médio**:\n",
        "        ⁃ Somente escola pública: 329\n",
        "        - Somente escola privada: 327\n",
        "\n",
        "        Essas informações destacam a distribuição de gênero, origem\n",
        "        geográfica, política afirmativa, e outros aspectos demograficos e\n",
        "        educacionais dos alunos.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0738c310",
      "metadata": {
        "id": "0738c310"
      },
      "outputs": [],
      "source": [
        "from guardrails import Guard\n",
        "from guardrails.hub import SimilarToDocument\n",
        "\n",
        "guard = Guard().use(\n",
        "    SimilarToDocument,\n",
        "    document=eureca_response,\n",
        "    threshold=0.7,\n",
        "    model=\"all-MiniLM-L6-v2\",\n",
        "    on_fail=\"exception\",\n",
        ")\n",
        "\n",
        "guard.validate(llm_response)\n",
        "\n",
        "try:\n",
        "    guard.validate(\n",
        "        \"\"\"\n",
        "        Graph neural networks (GNNs) are specialized neural networks that can operate on graph data\n",
        "        structures. These networks are designed to capture the relationships between nodes in a graph\n",
        "        and can be used for a variety of tasks, including node classification, link prediction, and graph classification.\n",
        "        \"\"\"\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}