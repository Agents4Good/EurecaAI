{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd818db-0d5f-4c22-9fe1-45707038e077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: guardrails-ai in /home/levi/.local/lib/python3.10/site-packages (0.6.2)\n",
      "Requirement already satisfied: boto3<2,>1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.35.99)\n",
      "Requirement already satisfied: coloredlogs<16.0.0,>=15.0.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (15.0.1)\n",
      "Requirement already satisfied: diff-match-patch<20230431,>=20230430 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (20230430)\n",
      "Requirement already satisfied: faker<26.0.0,>=25.2.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (25.9.2)\n",
      "Requirement already satisfied: griffe<0.37.0,>=0.36.9 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.36.9)\n",
      "Requirement already satisfied: guardrails-api-client<0.5.0,>=0.4.0a1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.4.0a1)\n",
      "Requirement already satisfied: guardrails-hub-types<0.0.5,>=0.0.4 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.0.4)\n",
      "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (4.23.0)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.3.24)\n",
      "Requirement already satisfied: litellm<2.0.0,>=1.37.14 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.58.2)\n",
      "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (4.9.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.30.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.59.7)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.24.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (1.29.0)\n",
      "Requirement already satisfied: pip>=22 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (24.3.1)\n",
      "Requirement already satisfied: pydantic<3.0,>=2.0.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.9.2)\n",
      "Requirement already satisfied: pydash<8.0.0,>=7.0.6 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (7.0.7)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.10.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (13.8.0)\n",
      "Requirement already satisfied: rstr<4.0.0,>=3.2.2 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (3.2.2)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.2 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (3.0.2)\n",
      "Requirement already satisfied: tenacity>=8.1.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.5.1 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (0.7.0)\n",
      "Requirement already satisfied: typer<0.13,>=0.9.0 in /home/levi/.local/lib/python3.10/site-packages (from typer[all]<0.13,>=0.9.0->guardrails-ai) (0.12.5)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.8.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-ai) (4.12.2)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.99 in /home/levi/.local/lib/python3.10/site-packages (from boto3<2,>1->guardrails-ai) (1.35.99)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/levi/.local/lib/python3.10/site-packages (from boto3<2,>1->guardrails-ai) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/levi/.local/lib/python3.10/site-packages (from boto3<2,>1->guardrails-ai) (0.10.4)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/levi/.local/lib/python3.10/site-packages (from coloredlogs<16.0.0,>=15.0.1->guardrails-ai) (10.0)\n",
      "Requirement already satisfied: colorama>=0.4 in /home/levi/.local/lib/python3.10/site-packages (from griffe<0.37.0,>=0.36.9->guardrails-ai) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-api-client<0.5.0,>=0.4.0a1->guardrails-ai) (75.8.0)\n",
      "Requirement already satisfied: urllib3<2.1.0,>=1.25.3 in /home/levi/.local/lib/python3.10/site-packages (from guardrails-api-client<0.5.0,>=0.4.0a1->guardrails-ai) (2.0.7)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.22.0->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.19.1)\n",
      "Requirement already satisfied: fqdn in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.5.1)\n",
      "Requirement already satisfied: idna in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (3.10)\n",
      "Requirement already satisfied: isoduration in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (3.0.0)\n",
      "Requirement already satisfied: rfc3339-validator in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (0.1.4)\n",
      "Requirement already satisfied: rfc3987 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.3.8)\n",
      "Requirement already satisfied: uri-template in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/levi/.local/lib/python3.10/site-packages (from jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (24.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (0.1.125)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/levi/.local/lib/python3.10/site-packages (from langchain-core<0.4,>=0.1->guardrails-ai) (24.1)\n",
      "Requirement already satisfied: aiohttp in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.10.5)\n",
      "Requirement already satisfied: click in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (8.1.7)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.23.0 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (6.11.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (3.1.4)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (1.0.1)\n",
      "Requirement already satisfied: tokenizers in /home/levi/.local/lib/python3.10/site-packages (from litellm<2.0.0,>=1.37.14->guardrails-ai) (0.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/levi/.local/lib/python3.10/site-packages (from openai<2.0.0,>=1.30.1->guardrails-ai) (4.66.5)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.65.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.63.2 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.69.0)\n",
      "Requirement already satisfied: opentelemetry-api~=1.15 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.29.0)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-proto==1.29.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (5.29.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /home/levi/.local/lib/python3.10/site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->guardrails-ai) (0.50b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/levi/.local/lib/python3.10/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/levi/.local/lib/python3.10/site-packages (from pydantic<3.0,>=2.0.0->guardrails-ai) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/levi/.local/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->guardrails-ai) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/levi/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/levi/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.31.0->guardrails-ai) (2024.12.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/levi/.local/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/levi/.local/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (2.18.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/levi/.local/lib/python3.10/site-packages (from tiktoken>=0.5.1->guardrails-ai) (2024.7.24)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/levi/.local/lib/python3.10/site-packages (from typer<0.13,>=0.9.0->typer[all]<0.13,>=0.9.0->guardrails-ai) (1.5.4)\n",
      "\u001b[33mWARNING: typer 0.12.5 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: exceptiongroup>=1.0.2 in /home/levi/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.30.1->guardrails-ai) (1.2.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/levi/.local/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->guardrails-ai) (1.16.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/levi/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/levi/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.23.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/levi/.local/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/levi/.local/lib/python3.10/site-packages (from jinja2<4.0.0,>=3.1.2->litellm<2.0.0,>=1.37.14->guardrails-ai) (2.1.5)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/levi/.local/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4,>=0.1->guardrails-ai) (3.10.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/levi/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->guardrails-ai) (0.1.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/levi/.local/lib/python3.10/site-packages (from aiohttp->litellm<2.0.0,>=1.37.14->guardrails-ai) (4.0.3)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/levi/.local/lib/python3.10/site-packages (from isoduration->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/levi/.local/lib/python3.10/site-packages (from tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (0.25.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /home/levi/.local/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format]<5.0.0,>=4.22.0->guardrails-ai) (2.9.0.20240316)\n",
      "Requirement already satisfied: filelock in /home/levi/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/levi/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm<2.0.0,>=1.37.14->guardrails-ai) (2024.9.0)\n"
     ]
    }
   ],
   "source": [
    "!python3.10 -m pip install guardrails-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9aeea11b-9bca-4c0f-a78c-426cec19fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: urllib3 in /home/levi/.local/lib/python3.10/site-packages (2.0.7)\n"
     ]
    }
   ],
   "source": [
    "!python3.10 -m pip install urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1c1971-914c-401c-b4eb-5c85f2c92a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mdetect_pii...\u001b[0m\n",
      "\u001b[2K\u001b[32m[====]\u001b[0m Fetching manifestst\n",
      "\u001b[2K\u001b[32m[=   ]\u001b[0m Downloading dependenciespendencies\n",
      "\u001b[2K\u001b[32m[ ===]\u001b[0m Running post-install setuptall setup\n",
      "\u001b[1A\u001b[2K✅Successfully installed guardrails/detect_pii version \u001b[1;36m0.0\u001b[0m.\u001b[1;36m5\u001b[0m!\n",
      "\n",
      "\n",
      "\u001b[1mImport validator:\u001b[0m\n",
      "from guardrails.hub import DetectPII\n",
      "\n",
      "\u001b[1mGet more info:\u001b[0m\n",
      "\u001b[4;94mhttps://hub.guardrailsai.com/validator/guardrails/detect_pii\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!guardrails hub install hub://guardrails/detect_pii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23baf400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mteste...\u001b[0m\n",
      "ERROR:guardrails-cli:404\n",
      "ERROR:guardrails-cli:Not Found\n",
      "ERROR:guardrails-cli:Failed to install hub://guardrails/teste\n"
     ]
    }
   ],
   "source": [
    "!guardrails hub install hub://guardrails/teste --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "367fc921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3.10 -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd1c6e5a-b167-43c1-bd27-bc5eb0764bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/levi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from guardrails.validators import (register_validator, Validator, FailResult, ValidationResult, PassResult)\n",
    "from guardrails import Guard, OnFailAction\n",
    "from guardrails.hub import DetectPII\n",
    "from typing import Any, Dict, Optional, Callable, List\n",
    "\n",
    "from presidio_analyzer import AnalyzerEngine, PatternRecognizer, RecognizerResult, Pattern\n",
    "import re\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "import unicodedata\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e59bd18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"./bert_tokenizer\") and os.path.isdir(\"./bert_model\"):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"./bert_tokenizer\")\n",
    "    model = BertModel.from_pretrained(\"./bert_model\")\n",
    "else:\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    \n",
    "    tokenizer.save_pretrained(\"./bert_tokenizer\")\n",
    "    model.save_pretrained(\"./bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5cea0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pointing(text:str) -> str:\n",
    "    \"\"\"\n",
    "        Remove pontuação do texto \n",
    "        Args:\n",
    "            text: O texto a ser tratado\n",
    "        \n",
    "        Returns:\n",
    "            O texto sem pontuação\n",
    "    \"\"\"\n",
    "    ans = \"\"\n",
    "    for c in text:\n",
    "          if unicodedata.category(c) != 'Po':\n",
    "               ans+=c\n",
    "    return ans \n",
    "\n",
    "\n",
    "def remove_accent(text:str) -> str:\n",
    "    \"\"\"\n",
    "        Remove os acentos das palavras do texto\n",
    "        Args:\n",
    "            text: O texto a ser tratado\n",
    "        \n",
    "        Returns:\n",
    "            O texto sem acentos\n",
    "    \"\"\"\n",
    "    nfkd = unicodedata.normalize('NFKD', text)\n",
    "    ans = \"\"\n",
    "    for c in nfkd:\n",
    "         if not unicodedata.combining(c):\n",
    "              ans += c\n",
    "    return ans\n",
    "\n",
    "\n",
    "def lemmatize(text: str) -> str:\n",
    "    \"\"\"\n",
    "        Aplica lematização no texto\n",
    "        Args:\n",
    "            text: O texto a ser tratado\n",
    "        Returns:\n",
    "            O texto lematizado\n",
    "    \"\"\"\n",
    "    nlp = spacy.load('pt_core_news_sm')\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "   \n",
    "   \n",
    "def remove_stopwords(text: str) -> str:  \n",
    "        \"\"\"\n",
    "            Remove as palavras irrelevantes do texto\n",
    "            Args:\n",
    "                words:  texto a ser tratado\n",
    "            \n",
    "            Returns:\n",
    "                Lista de string sem as palavras irrelevantes\n",
    "        \"\"\"\n",
    "        text_without_pointing_and_accent = remove_accent(remove_pointing(text))\n",
    "        lemmatized_text = lemmatize(text_without_pointing_and_accent)\n",
    "        words_splitted = lemmatized_text.split()     \n",
    "        stop_words = set(stopwords.words(\"portuguese\"))\n",
    "        relevant_text = \"\"\n",
    "        for word in words_splitted:\n",
    "            if word.lower() not in stop_words and len(word) > 2 and len(word) < 15:\n",
    "                relevant_text += re.sub(r'[^a-zA-Z0-9]', '', word.lower()) + \" \"\n",
    "                \n",
    "        return relevant_text\n",
    " \n",
    " \n",
    "def generate_embeddings(text: str) -> List[List]:\n",
    "       \n",
    "    \"\"\"\n",
    "    Retorna os embeddings do texto passado como parâmetro da função.\n",
    "    returns: Embeddings das palavras.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    embeddings = outputs.last_hidden_state\n",
    "    sentence_embedding = embeddings.mean(dim=1)\n",
    "    \n",
    "    return sentence_embedding\n",
    "\n",
    "\n",
    "def cosine_similarity(text1: str, text2: str) -> float:\n",
    "    \"\"\"\n",
    "    Calcula a similaridae cosseno entre dois textos.\n",
    "    Gera-se os embeddings para cada texto e em seguida, fazemos a similarida usando os embeddings. \n",
    "    returns: Grau de similaridade em um intervalo fechado entre 0 e 1.\n",
    "    \"\"\"\n",
    "    emb_text1 = generate_embeddings(text1)\n",
    "    emb_text2 = generate_embeddings(text2)\n",
    "    \n",
    "    emb_text1 = emb_text1.cpu().numpy()\n",
    "    emb_text2 = emb_text2.cpu().numpy()\n",
    "    \n",
    "    dot_product = np.dot(emb_text1, emb_text2.T)\n",
    "    text1Norm = np.linalg.norm(emb_text1)\n",
    "    text2Norm = np.linalg.norm(emb_text2)\n",
    "    \n",
    "    return dot_product / (text1Norm * text2Norm)\n",
    "\n",
    "\n",
    "def split_text(text, max_length: int = 10) -> List:\n",
    "        \n",
    "    \"\"\"\n",
    "    Divide o texto em alguns pedaços de frases.\n",
    "    returns: Lista de frases.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = [tokenizer.convert_tokens_to_string(tokens[i:i + max_length]) for i in range(0, len(tokens), max_length)]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def similarity_between_texts(text1, text2) -> float:\n",
    "        \n",
    "    \"\"\"\n",
    "    Calcula a similaridade entre dois textos.\n",
    "    returns: Similaridade cosseno.\n",
    "    \"\"\"\n",
    "    text1 = remove_stopwords(text1)\n",
    "    text2 = remove_stopwords(text2)\n",
    "    \n",
    "    print(text1)\n",
    "    print(text2)\n",
    "    \n",
    "    split_text1 = split_text(text1)\n",
    "    split_text2 = split_text(text2)\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    if len(split_text1) == 0 or len(split_text2) == 0:\n",
    "        return 0\n",
    "        \n",
    "    for text1 in split_text1:\n",
    "        for text2 in split_text2:\n",
    "            similarities.append(cosine_similarity(text1, text2)[0][0])\n",
    "            \n",
    "    media = np.mean(similarities)\n",
    "    print(media, similarities)\n",
    "    return media\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d60d85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_validator(name=\"guardrails/teste\", data_type=\"string\")\n",
    "class ValidadorDeSimilaridade(Validator):\n",
    "    def __init__(self, texto1: str, texto2: str, match_type: Optional[str] = None, on_fail: Optional[Callable] = None):        \n",
    "        super().__init__(on_fail=on_fail, match_type=match_type)\n",
    "        \n",
    "        self.texto1 = texto1\n",
    "        self.texto2 = texto2\n",
    "        \n",
    "    def validate(self, value: Any, metadata: Dict = {}) -> ValidationResult:\n",
    "        similarity = float(f\"{similarity_between_texts(self.texto1, self.texto2):.1f}\")\n",
    "        print(similarity)\n",
    "        \n",
    "        ideal_similarity = 0.7\n",
    "        if similarity < ideal_similarity:\n",
    "            print(f\"{value}: Similaridade baixa {similarity} (menor que {ideal_similarity})\")\n",
    "            return FailResult(error_message=\"Erro\")\n",
    "        \n",
    "        print(f\"{value}: Similaridade alta de {similarity} (igual ou acima de {ideal_similarity})\")\n",
    "        return PassResult()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d02db314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teste(texto1, texto2):\n",
    "    guard = Guard().use(\n",
    "        ValidadorDeSimilaridade(texto1=texto1, texto2=texto2)\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        guard.parse(\"Agente Inteligente\").model_validate\n",
    "        print(\"Passou no teste de similaridade cosseno!\")\n",
    "    except Exception as e:\n",
    "        print(\"Ocorreu um erro: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbfeb964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/levi/.local/lib/python3.10/site-packages/guardrails/validator_service/__init__.py:85: UserWarning: Could not obtain an event loop. Falling back to synchronous validation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lula \n",
      "carro \n",
      "0.7625983 [0.7625983]\n",
      "0.8\n",
      "Agente Inteligente: Similaridade alta de 0.8 (igual ou acima de 0.7)\n",
      "Passou no teste de similaridade cosseno!\n"
     ]
    }
   ],
   "source": [
    "texto1 = \"\"\"\n",
    "lula \n",
    "\"\"\"\n",
    "\n",
    "texto2 = \"\"\"\n",
    "carro\n",
    "\"\"\"\n",
    "\n",
    "teste(texto1=texto1, texto2=texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed11eb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onde sao aluno ciencia computacao liste todo estado \n",
      "aluno ciencia computacao vir diverso estado incluir pernambuco rio janeiro sao paulo minas gerais bahia sao algum exemplo estado origem aluno \n",
      "0.659812 [0.8117717, 0.74846905, 0.5817227, 0.6511542, 0.5596056, 0.6946472, 0.6640316, 0.5304727, 0.8176472, 0.5385981]\n",
      "0.7\n",
      "Agente Inteligente: Similaridade alta de 0.7 (igual ou acima de 0.7)\n",
      "Passou no teste de similaridade cosseno!\n"
     ]
    }
   ],
   "source": [
    "texto1 = \"\"\"\n",
    "de onde sao os alunos de ciencia da computacao? liste todos os estados\n",
    "\"\"\"\n",
    "\n",
    "texto2 = \"\"\"\n",
    "Os alunos de Ciência da Computação vêm de diversos estados,\n",
    "incluindo:\n",
    "\n",
    "\n",
    "Pernambuco (PE)\n",
    "Rio de Janeiro (RJ)\n",
    "São Paulo (SP)\n",
    "Minas Gerais (MG)\n",
    "Bahia (BA)\n",
    "\n",
    "\n",
    "Esses sao alguns exemplos dos estados de origem dos alunos.\"\"\"\n",
    "\n",
    "teste(texto1=texto1, texto2=texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b8c60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resumo informacoes relevante sobre aluno curso ciencia computacao \n",
      "alunas feminino quantidade total 183 estado civil solteiro 175 casado3 nacionalidade 100 brasileira principais estado pb139 pe17 idade media 2168 ano minima ano maxima ano politica afirmativa bon estadual corraca branca parda renda per capita media 678 tipo ensino medio somente escola publicar somente escola privada89 alunos masculino quantidade total 658 estado civil solteiro 641 casado6 nacionalidade brasileira 657 brasileiro estrangeiro principais estado pb498 pe idade media 2187 ano minima ano maxima ano politica afirmativa bon estadual 127 l271 corraca branca 337 parda 271 renda per capita media 705 tipo ensino medio somente escola publicar 329 somente escola privado 327 informacoes destacar distribuicao genero origem geografico politico afirmativo outro aspecto demografico educacional aluno \n",
      "0.6869465 [0.7530056, 0.6495437, 0.60388887, 0.58420134, 0.5304056, 0.79059666, 0.63076955, 0.52720684, 0.73523057, 0.7651861, 0.5958135, 0.59845686, 0.6373084, 0.5946354, 0.65009886, 0.6155619, 0.7394656, 0.6217252, 0.52726763, 0.69763345, 0.64946634, 0.7875221, 0.6949274, 0.72271824, 0.78672427, 0.69092065, 0.748745, 0.7027178, 0.6960589, 0.6659649, 0.6343809, 0.7731058, 0.71414196, 0.5952825, 0.7102794, 0.77441543, 0.6460071, 0.6759125, 0.7034705, 0.7066323, 0.6761002, 0.6991364, 0.78605366, 0.7455781, 0.6066392, 0.7470393, 0.7161876, 0.77844, 0.7596874, 0.7202754, 0.7887549, 0.76992863]\n",
      "0.7\n",
      "Agente Inteligente: Similaridade alta de 0.7 (igual ou acima de 0.7)\n",
      "Passou no teste de similaridade cosseno!\n"
     ]
    }
   ],
   "source": [
    "texto1 = \"\"\"\n",
    "está um resumo das informações relevantes sobre os alunos do curso de Ciência da Computação\n",
    "\"\"\"\n",
    "\n",
    "texto2 = \"\"\"\n",
    "### Alunas (Feminino)\n",
    "\n",
    "- **Quantidade Total**: 183\n",
    "- **Estado Civil**\n",
    " - Solteiro: 175\n",
    " - Casado:3\n",
    "- **Nacionalidade**: 100% Brasileira\n",
    "- **Principais Estados**\n",
    " -PB:139\n",
    " - PE:17\n",
    "- **Idade**:\n",
    " - Média: 21.68 anos\n",
    " - Mínima: 17 anos\n",
    " - Máxima: 39 anos\n",
    "- **Política Afirmativa**:\n",
    " - Bon. estadual: 40\n",
    " - L2: 26\n",
    "- **Cor/Raça**:\n",
    "  -Branca: 92\n",
    "  -Parda: 83\n",
    "- **Renda Per Capita**:\n",
    " - Média: 6.78\n",
    "- **Tipo de Ensino Médio**\n",
    " - Somente escola pública: 93\n",
    " - Somente escola privada:89\n",
    "\n",
    "### Alunos (Masculino)\n",
    "\n",
    "⁃ **Quantidade Total**: 658\n",
    "- **Estado Civil**:\n",
    "⁃ Solteiro: 641\n",
    " - Casado:6\n",
    "- **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\n",
    "- **Principais Estados**:\n",
    " -PB:498\n",
    " -PE: 47\n",
    "⁃ **Idade**:\n",
    " ⁃ Média: 21.87 anos\n",
    " - Minima: 17 anos\n",
    " ⁃ Máxima: 43 anos\n",
    "- **Política Afirmativa**\n",
    " - Bon. estadual: 127\n",
    " - L2:71\n",
    "- **Cor/Raca**:\n",
    " ⁃ Branca: 337\n",
    " -Parda: 271\n",
    "- **Renda Per Capita**:\n",
    " - Média: 7.05\n",
    "- **Tipo de Ensino Médio**:\n",
    " ⁃ Somente escola pública: 329\n",
    "- Somente escola privada: 327\n",
    "\n",
    "Essas informações destacam a distribuição de gênero, origem\n",
    "geográfica, política afirmativa, e outros aspectos demograficos e\n",
    "educacionais dos alunos.\n",
    "\"\"\"\n",
    "\n",
    "teste(texto1, texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a4f50c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lula presidente brasil \n",
      "lula nao presidente brasil \n",
      "0.9101971 [0.9101971]\n",
      "0.9\n",
      "Agente Inteligente: Similaridade alta de 0.9 (igual ou acima de 0.7)\n",
      "Passou no teste de similaridade cosseno!\n"
     ]
    }
   ],
   "source": [
    "texto1 = \"Lula é o presidente do Brasil\"\n",
    "texto2 = \"Lula não é o presidente do Brasil\"\n",
    "\n",
    "teste(texto1=texto1, texto2=texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0908f440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing hub:\u001b[35m/\u001b[0m\u001b[35m/guardrails/\u001b[0m\u001b[95mpii...\u001b[0m\n",
      "ERROR:guardrails-cli:404\n",
      "ERROR:guardrails-cli:Not Found\n",
      "ERROR:guardrails-cli:Failed to install hub://guardrails/pii\n"
     ]
    }
   ],
   "source": [
    "!guardrails hub install hub://guardrails/pii --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07ba3384",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed for field with errors: A minha matricula é o seguinte: <MATRICULA>, busque informaões sobre ela\n"
     ]
    }
   ],
   "source": [
    "@register_validator(name=\"guardrails/enrollment\", data_type=\"string\")\n",
    "class PIIValidator(Validator):\n",
    "    def __init__(self, on_match: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
    "        super().__init__(on_match=on_match, on_fail=on_fail)\n",
    "        \n",
    "    def validate(self, value: str, metadata: Dict = {}) -> ValidationResult:\n",
    "        year = str(dt.datetime.now().year)[2:]\n",
    "        \n",
    "        enrollment = r\"\\b\\d{1}[1-\" + year[0] + r\"]\" + r\"[0-\" + year[1] + r\"]\" + r\"[12]\\d{5}\\b\"\n",
    "        enrollment_pattern = Pattern(name=\"Enrollment_Pattern\", regex=enrollment, score=0.6)\n",
    "        \n",
    "        enrollment_recognizer = PatternRecognizer(name=\"MATRICULA\", patterns=[enrollment_pattern], supported_entity=\"Enrollment_Pattern\", supported_language=\"en\")\n",
    "        \n",
    "        analyzer = AnalyzerEngine()\n",
    "        analyzer.registry.add_recognizer(enrollment_recognizer)\n",
    "        \n",
    "        results = analyzer.analyze(text=value, entities=[\"Enrollment_Pattern\"], language=\"en\")\n",
    "        \n",
    "        if results:\n",
    "            for result in results:\n",
    "                start, end = result.start, result.end\n",
    "                value = value[:start] + \"<MATRICULA>\" + value[end:]\n",
    "            return FailResult(error_message=value)\n",
    "        \n",
    "        return PassResult()\n",
    "\n",
    "\n",
    "\n",
    "guardas_eureca = Guard().use(PIIValidator)\n",
    "\n",
    "try:\n",
    "    guardas_eureca.parse(\"A minha matricula é o seguinte: 221199999, busque informaões sobre ela\").model_validate\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3185903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - CreditCardRecognizer supported languages: pl, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNifRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - EsNieRecognizer supported languages: es, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItDriverLicenseRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItFiscalCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItVatCodeRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItIdentityCardRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - ItPassportRecognizer supported languages: it, registry supported languages: en\n",
      "WARNING:presidio-analyzer:Recognizer not added to registry because language is not supported by registry - PlPeselRecognizer supported languages: pl, registry supported languages: en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation failed for field with errors: O meu CPF é o seguinte: <CPF>, busque informaões sobre ele\n"
     ]
    }
   ],
   "source": [
    "\n",
    "@register_validator(name=\"guardrails/cpf\", data_type=\"string\")\n",
    "class PIIValidatorCPF(Validator):\n",
    "    def __init__(self, on_match: Optional[str] = None, on_fail: Optional[Callable] = None):\n",
    "        super().__init__(on_match=on_match, on_fail=on_fail)\n",
    "        \n",
    "    def validate(self, value: str, metadata: Dict = {}) -> ValidationResult:\n",
    "        year = str(dt.datetime.now().year)[2:]\n",
    "        \n",
    "        cpf_regex = r\"\\b\\d{3}\\.*\\d{3}\\.*\\d{3}-*\\d{2}\\b\"\n",
    "        cpf_pattern = Pattern(name=\"CPF_Pattern\", regex=cpf_regex, score=0.6)\n",
    "        \n",
    "        cpf_recognizer = PatternRecognizer(name=\"MATRICULA\", patterns=[cpf_pattern], supported_entity=\"CPF_Pattern\", supported_language=\"en\")\n",
    "        \n",
    "        analyzer = AnalyzerEngine()\n",
    "        analyzer.registry.add_recognizer(cpf_recognizer)\n",
    "        \n",
    "        results = analyzer.analyze(text=value, entities=[\"CPF_Pattern\"], language=\"en\")\n",
    "        \n",
    "        if results:\n",
    "            for result in results:\n",
    "                start, end = result.start, result.end\n",
    "                value = value[:start] + \"<CPF>\" + value[end:]\n",
    "            return FailResult(error_message=value)\n",
    "        \n",
    "        return PassResult()\n",
    "\n",
    "\n",
    "\n",
    "guardas_eureca = Guard().use(PIIValidatorCPF)\n",
    "\n",
    "try:\n",
    "    result = guardas_eureca.parse(\"O meu CPF é o seguinte: 99999999999, busque informaões sobre ele\").model_validate\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cadd8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Meus emails são <EMAIL_ADDRESS> ou <EMAIL_ADDRESS> ou <EMAIL_ADDRESS> e <EMAIL_ADDRESS>; \n",
      "e os meus números de telefones são esses <PHONE_NUMBER> ou <PHONE_NUMBER> ou <PHONE_NUMBER> e <PHONE_NUMBER>, \n",
      "busque no <URL> ou <URL>. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "guarda_email = Guard().use(DetectPII(pii_entities=\"pii\", on_fail=\"fix\"))\n",
    "\n",
    "text = \"\"\"\n",
    "Meus emails são demo@lol.com ou dominio@gmail.com ou dominio@hotmail.com e dominio@hotmail.com.br; \n",
    "e os meus números de telefones são esses (99) 999999999 ou (99)999999999 ou 99999999999 e 99999999999, \n",
    "busque no google.com.br ou uol.com. \n",
    "\"\"\"\n",
    "output = guarda_email.parse(\n",
    "    llm_output=text,\n",
    "    metadata={\"pii_entities\": [\"EMAIL_ADDRESS\", \"URL\", \"PHONE_NUMBER\"]},\n",
    ")\n",
    "\n",
    "print(output.validated_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e9ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-20 16:56:30.276863: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-20 16:56:30.380682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737402990.424061   34279 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737402990.436296   34279 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-20 16:56:30.539567: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "@register_validator(name=\"hallucination_detector\", data_type=\"string\")\n",
    "class HallucinationValidation(Validator):\n",
    "    def __init__(\n",
    "            self, \n",
    "            embedding_model: Optional[str] = None,\n",
    "            entailment_model: Optional[str] = None,\n",
    "            sources: Optional[List[str]] = None,\n",
    "            **kwargs\n",
    "        ):\n",
    "        if embedding_model is None:\n",
    "            embedding_model = 'all-MiniLM-L6-v2'\n",
    "        self.embedding_model = SentenceTransformer(embedding_model)\n",
    "\n",
    "        self.sources = sources\n",
    "        \n",
    "        if entailment_model is None:\n",
    "            entailment_model = 'GuardrailsAI/finetuned_nli_provenance'\n",
    "        self.nli_pipeline = pipeline(\"text-classification\", model=entailment_model)\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def validate(\n",
    "        self, value: str, metadata: Optional[Dict[str, str]] = None\n",
    "    ) -> ValidationResult:\n",
    "        sentences = self.split_sentences(value)\n",
    "\n",
    "        relevant_sources = self.find_relevant_sources(sentences, self.sources)\n",
    "\n",
    "        entailed_sentences = []\n",
    "        hallucinated_sentences = []\n",
    "        for sentence in sentences:\n",
    "            is_entailed = self.check_entailment(sentence, relevant_sources)\n",
    "            if not is_entailed:\n",
    "                hallucinated_sentences.append(sentence)\n",
    "            else:\n",
    "                entailed_sentences.append(sentence)\n",
    "        \n",
    "        if len(hallucinated_sentences) > 0:\n",
    "            return FailResult(\n",
    "                error_message=f\"Alucinação detectada: {hallucinated_sentences}\",\n",
    "            )\n",
    "        \n",
    "        return PassResult()\n",
    "\n",
    "    def split_sentences(self, text: str) -> List[str]:\n",
    "        return nltk.sent_tokenize(text)\n",
    "\n",
    "    def find_relevant_sources(self, sentences: str, sources: List[str]) -> List[str]:\n",
    "        source_embeds = self.embedding_model.encode(sources)\n",
    "        sentence_embeds = self.embedding_model.encode(sentences)\n",
    "\n",
    "        relevant_sources = []\n",
    "\n",
    "        for sentence_idx in range(len(sentences)):\n",
    "            sentence_embed = sentence_embeds[sentence_idx, :].reshape(1, -1)\n",
    "            cos_similarities = np.sum(np.multiply(source_embeds, sentence_embed), axis=1)\n",
    "            top_sources = np.argsort(cos_similarities)[::-1][:5]\n",
    "            top_sources = [i for i in top_sources if cos_similarities[i] > 0.8]\n",
    "\n",
    "            relevant_sources.extend([sources[i] for i in top_sources])\n",
    "\n",
    "        return relevant_sources\n",
    "    \n",
    "    def check_entailment(self, sentence: str, sources: List[str]) -> bool:\n",
    "        for source in sources:\n",
    "            output = self.nli_pipeline({'text': source, 'text_pair': sentence})\n",
    "            if output['label'] == 'entailment':\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6041145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at GuardrailsAI/finetuned_nli_provenance and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: ./saved_models/finetuned_nli_provenance\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"GuardrailsAI/finetuned_nli_provenance\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "save_directory = \"./saved_models/finetuned_nli_provenance\"\n",
    "\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "model.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Modelo salvo em: {save_directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c230b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"./saved_models/finetuned_nli_provenance\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_directory)\n",
    "model = AutoModel.from_pretrained(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef2b3d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Guard' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m guard \u001b[38;5;241m=\u001b[39m \u001b[43mGuard\u001b[49m()\u001b[38;5;241m.\u001b[39muse(\n\u001b[1;32m      2\u001b[0m     HallucinationValidation(\n\u001b[1;32m      3\u001b[0m         embedding_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m         entailment_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_models/finetuned_nli_provenance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m         sources\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m        ### Alunas (Feminino)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m        - **Quantidade Total**: 183\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m        - **Estado Civil**\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m        - Solteiro: 175\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m        - Casado:3\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m        - **Nacionalidade**: 100% Brasileira\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m        - **Principais Estados**\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m        -PB:139\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m        - PE:17\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m        - **Idade**:\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m        - Média: 21.68 anos\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m        - Mínima: 17 anos\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m        - Máxima: 39 anos\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m        - **Política Afirmativa**:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m        - Bon. estadual: 40\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m        - L2: 26\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m        - **Cor/Raça**:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m          -Branca: 92\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m          -Parda: 83\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m        - **Renda Per Capita**:\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;03m        - Média: 6.78\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m        - **Tipo de Ensino Médio**\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m        - Somente escola pública: 93\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        - Somente escola privada:89\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m        ### Alunos (Masculino)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m        ⁃ **Quantidade Total**: 658\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;03m        - **Estado Civil**:\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m        ⁃ Solteiro: 641\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m        - Casado:6\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m        - **Principais Estados**:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m        -PB:498\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m        -PE: 47\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03m        ⁃ **Idade**:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03m        ⁃ Média: 21.87 anos\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124;03m        - Minima: 17 anos\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m        ⁃ Máxima: 43 anos\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m        - **Política Afirmativa**\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m        - Bon. estadual: 127\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m        - L2:71\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m        - **Cor/Raca**:\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m        ⁃ Branca: 337\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m        -Parda: 271\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        - **Renda Per Capita**:\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        - Média: 7.05\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m        - **Tipo de Ensino Médio**:\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m        ⁃ Somente escola pública: 329\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        - Somente escola privada: 327\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m        Essas informações destacam a distribuição de gênero, origem\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m        geográfica, política afirmativa, e outros aspectos demograficos e\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m        educacionais dos alunos.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m        \"\"\"\u001b[39;00m],\n\u001b[1;32m     63\u001b[0m         on_fail\u001b[38;5;241m=\u001b[39mOnFailAction\u001b[38;5;241m.\u001b[39mEXCEPTION\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     67\u001b[0m guard\u001b[38;5;241m.\u001b[39mvalidate(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Guard' is not defined"
     ]
    }
   ],
   "source": [
    "guard = Guard().use(\n",
    "    HallucinationValidation(\n",
    "        embedding_model='all-MiniLM-L6-v2',\n",
    "        entailment_model='./saved_models/finetuned_nli_provenance',\n",
    "        sources=[\n",
    "        \"\"\"\n",
    "        ### Alunas (Feminino)\n",
    "\n",
    "        - **Quantidade Total**: 183\n",
    "        - **Estado Civil**\n",
    "        - Solteiro: 175\n",
    "        - Casado:3\n",
    "        - **Nacionalidade**: 100% Brasileira\n",
    "        - **Principais Estados**\n",
    "        -PB:139\n",
    "        - PE:17\n",
    "        - **Idade**:\n",
    "        - Média: 21.68 anos\n",
    "        - Mínima: 17 anos\n",
    "        - Máxima: 39 anos\n",
    "        - **Política Afirmativa**:\n",
    "        - Bon. estadual: 40\n",
    "        - L2: 26\n",
    "        - **Cor/Raça**:\n",
    "          -Branca: 92\n",
    "          -Parda: 83\n",
    "        - **Renda Per Capita**:\n",
    "        - Média: 6.78\n",
    "        - **Tipo de Ensino Médio**\n",
    "        - Somente escola pública: 93\n",
    "        - Somente escola privada:89\n",
    "\n",
    "        ### Alunos (Masculino)\n",
    "\n",
    "        ⁃ **Quantidade Total**: 658\n",
    "        - **Estado Civil**:\n",
    "        ⁃ Solteiro: 641\n",
    "        - Casado:6\n",
    "        - **Nacionalidade**: Predominantemente Brasileira (657 brasileiros, 1 estrangeiro)\n",
    "        - **Principais Estados**:\n",
    "        -PB:498\n",
    "        -PE: 47\n",
    "        ⁃ **Idade**:\n",
    "        ⁃ Média: 21.87 anos\n",
    "        - Minima: 17 anos\n",
    "        ⁃ Máxima: 43 anos\n",
    "        - **Política Afirmativa**\n",
    "        - Bon. estadual: 127\n",
    "        - L2:71\n",
    "        - **Cor/Raca**:\n",
    "        ⁃ Branca: 337\n",
    "        -Parda: 271\n",
    "        - **Renda Per Capita**:\n",
    "        - Média: 7.05\n",
    "        - **Tipo de Ensino Médio**:\n",
    "        ⁃ Somente escola pública: 329\n",
    "        - Somente escola privada: 327\n",
    "\n",
    "        Essas informações destacam a distribuição de gênero, origem\n",
    "        geográfica, política afirmativa, e outros aspectos demograficos e\n",
    "        educacionais dos alunos.\n",
    "        \"\"\"],\n",
    "        on_fail=OnFailAction.EXCEPTION\n",
    "    )\n",
    ")\n",
    "\n",
    "guard.validate(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8520a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total_success': 11, 'total_errors': 1, 'success_rate': 91.66666666666666, 'errors_rate': 8.333333333333332, 'errors_ocurred': [{'sentence': 'Quantos professores lecionam no curso de Psicologia', 'expected_output': 'professor', 'model_predict': {'sentence': 'Quantos professores lecionam no curso de Psicologia', 'output_expected': 'professor', 'output_model': 'curso', 'score': 0.8182957172393799}}]}\n",
      "Obteve 11 acertos (91.67%) e 1 erro(s) (8.33%) de 12 amostras\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "CLASSIFIER = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model='facebook/bart-large-mnli',\n",
    "    hypothesis_template=\"Verifique em qual tópico o texto acima melhor se adequa: {}.\",\n",
    "    multi_label=True,\n",
    ")\n",
    "\n",
    "dataset = [\n",
    "    (\"Quais são as disciplinas oferecidas no curso de Matemática\", \"disciplina\"),\n",
    "    (\"Quantos cursos a universidade oferece\", \"curso\"),\n",
    "    (\"Qual o calendário acadêmico deste semestre\", \"período\"),\n",
    "    (\"Onde os alunos do curso de Engenharia são matriculados\", \"estudante\"),\n",
    "    (\"Quantos professores tem em toda a universidade\", \"professor\"),\n",
    "    (\"Quantos professores lecionam no curso de Psicologia\", \"professor\"),\n",
    "    (\"Qual livro aborda o estudo de inteligência artificial\", \"livro\"),\n",
    "    (\"Quais são os livros recomendados para o curso de Direito\", \"livro\"),\n",
    "    (\"Quais as disciplinas do curso de Engenharia Civil\", \"disciplina\"),\n",
    "    (\"Qual o período de férias da universidade\", \"período\"),\n",
    "    (\"Quantos alunos estão matriculados no curso de ciencia da computacao\", \"estudante\"),\n",
    "    (\"Quais são os livros que falam sobre estatística\", \"livro\"),\n",
    "]\n",
    "\n",
    "class TopicTest:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.vocab_size = len(dataset)\n",
    "        self.result = None\n",
    "        self.topics = []\n",
    "        self.test()\n",
    "\n",
    "    def test(self):\n",
    "        total_success = 0\n",
    "        total_errors = 0\n",
    "        errors = []\n",
    "        self.topics = list(set([topic for _, topic in self.dataset]))\n",
    "        \n",
    "        for (input, output) in dataset:\n",
    "            classified_output = CLASSIFIER(input, self.topics)\n",
    "            classifier = classified_output['labels'][0]\n",
    "            \n",
    "            if classifier == output:\n",
    "                total_success += 1\n",
    "            else:\n",
    "                errors.append({\"sentence\": input, \"output_expected\": output, \"output_model\": classifier, \"score\": classified_output['scores'][0]})\n",
    "                total_errors += 1\n",
    "\n",
    "        success_rate = total_success / self.vocab_size * 100\n",
    "        errors_rate = total_errors / self.vocab_size * 100\n",
    "        \n",
    "        self.result = {\n",
    "            \"total_success\": total_success,\n",
    "            \"total_errors\": total_errors,\n",
    "            \"success_rate\": success_rate, \n",
    "            \"errors_rate\": errors_rate,\n",
    "            \"errors_ocurred\": errors\n",
    "        }\n",
    "    \n",
    "    def explain_test(self):\n",
    "        print(f'Obteve {self.result[\"total_success\"]} acertos ({self.result[\"success_rate\"]:.2f}%) e {self.result[\"total_errors\"]} erro(s) ({self.result[\"errors_rate\"]:.2f}%) de {tester.vocab_size} amostras')\n",
    "\n",
    "tester = TopicTest(dataset=dataset)\n",
    "print(tester.result)    \n",
    "tester.explain_test() \n",
    "\n",
    "input = \"\"\n",
    "classified_output = CLASSIFIER(input, [\"disciplina\", \"curso\", \"período\", \"estudante\", \"professor\", \"livro\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
